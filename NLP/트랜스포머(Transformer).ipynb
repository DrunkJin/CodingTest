{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd81441",
   "metadata": {},
   "source": [
    "[출처 : https://wikidocs.net/31379](https://wikidocs.net/31379)\n",
    "# 1) 트랜스포머(Transformer)\n",
    "\n",
    "* 어텐션 메커니즘에 대한 이해가 필요함<br>\n",
    "<br>\n",
    "트랜스포머(Transformer)는 2017년 구글이 발표한 논문인 \"Attention is all you need\"에서 나온 모델로 기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델입니다.<br>\n",
    "<br>\n",
    "이 모델은 RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 번역 성능에서도 RNN보다 우수한 성능을 보여주었습니다.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70da8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c407a",
   "metadata": {},
   "source": [
    "## 1. 기존의 seq2seq 모델의 한계\n",
    "기존의 seq2seq를 상기해봅시다. <br>\n",
    "<br>\n",
    "기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어져 있었습니다. <br>\n",
    "<br>\n",
    "여기서 인코더는 입력 시퀀스를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해서 출력 시퀀스를 만들어냈습니다. <br>\n",
    "<br>\n",
    "하지만 이러한 구조는 인코더가 입력 시퀀스를 하나의 벡터로 압축하는 과정에서 입력 시퀀스의 정보가 일부 손실된다는 단점이 있었고, 이를 보정하기 위해 어텐션이 사용되었습니다. <br>\n",
    "<br>\n",
    "그런데 어텐션을 RNN의 보정을 위한 용도로서 사용하는 것이 아니라 어텐션만으로 인코더와 디코더를 만들어보면 어떨까요?\n",
    "<br>\n",
    "<br>\n",
    "## 2. 트랜스포머(Transformer)의 주요 하이퍼파라미터\n",
    "\n",
    "시작에 앞서 트랜스포머의 하이퍼파라미터를 정의합니다.<br>\n",
    "<br>\n",
    "각 하이퍼파라미터의 의미에 대해서는 뒤에서 설명하기로하고, 여기서는 트랜스포머에는 이러한 하이퍼파라미터가 존재한다는 정도로만 이해해보겠습니다. <br>\n",
    "<br>\n",
    "아래에서 정의하는 수치는 트랜스포머를 제안한 논문에서 사용한 수치로 하이퍼파라미터는 사용자가 모델 설계시 임의로 변경할 수 있는 값들입니다.<br>\n",
    "<br>\n",
    "$d_{model} = 512$ <br>\n",
    "<br>\n",
    "트랜스포머의 인코더와 디코더에서의 정해진 입력과 출력의 크기를 의미합니다. <br>\n",
    "<br>\n",
    "임베딩 벡터의 차원 또한 $d_{model}$이며, 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때에도 이 차원을 유지합니다. <br>\n",
    "<br>논문에서는 512입니다.<br>\n",
    "<br>\n",
    "$\\text{num_layers} = 6$<br>\n",
    "<br>\n",
    "트랜스포머에서 하나의 인코더와 디코더를 층으로 생각하였을 때, 트랜스포머 모델에서 인코더와 디코더가 총 몇 층으로 구성되었는지를 의미합니다. <br>\n",
    "<br>\n",
    "논문에서는 인코더와 디코더를 각각 총 6개 쌓았습니다.<br>\n",
    "<br>\n",
    "$\\text{num_heads} = 8$<br>\n",
    "<br>\n",
    "트랜스포머에서는 어텐션을 사용할 때, 한 번 하는 것 보다 여러 개로 분할해서 병렬로 어텐션을 수행하고 결과값을 다시 하나로 합치는 방식을 택했습니다. 이때 이 병렬의 개수를 의미합니다.<br>\n",
    "<br>\n",
    "$d_{ff} = 2048$\n",
    "<br>\n",
    "트랜스포머 내부에는 피드 포워드 신경망이 존재하며 해당 신경망의 은닉층의 크기를 의미합니다. 피드 포워드 신경망의 입력층과 출력층의 크기는 $d_{model}$입니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "## 3. 트랜스포머(Transformer)\n",
    "![](https://wikidocs.net/images/page/31379/transformer1.PNG)\n",
    "<br>\n",
    "트랜스포머는 RNN을 사용하지 않지만 기존의 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고, 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 유지하고 있습니다. <br>\n",
    "<br>\n",
    "이전 seq2seq 구조에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점(time step)을 가지는 구조였다면 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조입니다.<br>\n",
    "<br>트랜스포머를 제안한 논문에서는 인코더와 디코더의 개수를 각각 6개 사용하였습니다.<br>\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer2.PNG)\n",
    "위의 그림은 인코더와 디코더가 6개씩 존재하는 트랜스포머의 구조를 보여줍니다. <br>\n",
    "<br>\n",
    "인코더와 디코더가 각각 여러 개 쌓여있다는 의미를 사용할 때는 알파벳 s를 뒤에 붙여 encoders, decoders라고 표현하겠습니다.\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer4_final_final_final.PNG)\n",
    "위의 그림은 인코더로부터 정보를 전달받아 디코더가 출력 결과를 만들어내는 트랜스포머 구조를 보여줍니다.<br>\n",
    "<br>\n",
    "디코더는 마치 기존의 seq2seq 구조처럼 시작 심볼 $<sos>$를 입력으로 받아 종료 심볼 $<eos>$가 나올 때까지 연산을 진행합니다. <br>\n",
    "<br>\n",
    "이는 RNN은 사용되지 않지만 여전히 인코더-디코더의 구조는 유지되고 있음을 보여줍니다.\n",
    "<br>\n",
    "트랜스포머의 내부 구조를 조금씩 확대해가는 방식으로 트랜스포머를 이해해봅시다. <br>\n",
    "<br>\n",
    "\n",
    "우선 인코더와 디코더의 구조를 이해하기 전에 트랜스포머의 입력에 대해서 이해해보겠습니다.<br>\n",
    "\n",
    "트랜스포머의 인코더와 디코더는 단순히 각 단어의 임베딩 벡터들을 입력받는 것이 아니라 임베딩 벡터에서 조정된 값을 입력받는데 이에 대해서 알아보기 위해 입력 부분을 확대해보겠습니다.<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ced278",
   "metadata": {},
   "source": [
    "## 4. 포지셔널 인코딩(Positional Encoding)\n",
    "   \n",
    "   \n",
    "트랜스포머의 내부를 이해하기 전에 우선 **트랜스포머의 입력**에 대해서 알아보겠습니다. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "RNN이 자연어 처리에서 유용했던 이유는 단어의 위치에 따라 단어를 순차적으로 입력받아서 처리하는 RNN의 특성으로 인해 각 단어의 위치 정보(position information)를 가질 수 있다는 점에 있었습니다.<br>\n",
    "<br>\n",
    "하지만 트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있습니다. <br>\n",
    "<br>\n",
    "트랜스포머는 단어의 위치 정보를 얻기 위해서 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용하는데, 이를 포지셔널 인코딩(positional encoding)이라고 합니다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer5_final_final.PNG)\n",
    "<br>\n",
    "위의 그림은 입력으로 사용되는 임베딩 벡터들이 트랜스포머의 입력으로 사용되기 전에 포지셔널 인코딩의 값이 더해지는 것을 보여줍니다. <br>\n",
    "임베딩 벡터가 인코더의 입력으로 사용되기 전 포지셔널 인코딩값이 더해지는 과정을 시각화하면 아래와 같습니다.<br>\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer6_final.PNG)\n",
    "포지셔널 인코딩 값들은 어떤 값이기에 위치 정보를 반영해줄 수 있는 것일까요? 트랜스포머는 위치 정보를 가진 값을 만들기 위해서 아래의 두 개의 함수를 사용합니다.<br>\n",
    "<br>\n",
    "$PE_{(pos,\\ 2i)}=sin(pos/10000^{2i/d_{model}})$<br>\n",
    "$PE_{(pos,\\ 2i+1)}=cos(pos/10000^{2i/d_{model}})$<br>\n",
    "<br>\n",
    "사인 함수와 코사인 함수의 그래프를 상기해보면 요동치는 값의 형태를 생각해볼 수 있는데, 트랜스포머는 사인 함수와 코사인 함수의 값을 임베딩 벡터에 더해주므로서 단어의 순서 정보를 더하여 줍니다. <br>\n",
    "<br>\n",
    "그런데 위의 두 함수에는 $pos,i, d_{model}$등의 생소한 변수들이 있습니다. <br>\n",
    "위의 함수를 이해하기 위해서는 위에서 본 임베딩 벡터와 포지셔널 인코딩의 덧셈은 사실 임베딩 벡터가 모여 만들어진 문장 행렬과 포지셔널 인코딩 행렬의 덧셈 연산을 통해 이루어진다는 점을 이해해야 합니다.<br>\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer7.PNG)\n",
    "$pos$는 입력 문장에서의 임베딩 벡터의 위치를 나타내며, $i$는 임베딩 벡터 내의 차원의 인덱스를 의미합니다. <br>\n",
    "<br>\n",
    "위의 식에 따르면 임베딩 벡터 내의 각 차원의 인덱스가 짝수인 경우에는 사인 함수의 값을 사용하고 홀수인 경우에는 코사인 함수의 값을 사용합니다. <br>\n",
    "<br>\n",
    "위의 수식에서 $(pos,\\ 2i)$일 때는 사인 함수를 사용하고, $(pos,\\ 2i+1)$일 때는 코사인 함수를 사용하고 있음을 주목합시다.<br>\n",
    "<br>\n",
    "또한 위의 식에서 $d_{model}$은 트랜스포머의 모든 층에서 출력 차원을 의미하는 트랜스포머의 하이퍼파라미터입니다.<br>\n",
    "<br>\n",
    "앞으로 보게 될 트랜스포머의 각종 구조에서 $d_{model}$의 값이 계속해서 등장하는 이유입니다. <br>\n",
    "<br>\n",
    "임베딩 벡터 또한 $d_{model}$의 차원을 가지는데 위의 그림에서는 마치 4로 표현되었지만 실제 논문에서는 512의 값을 가집니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "위와 같은 포지셔널 인코딩 방법을 사용하면 순서 정보가 보존되는데, 예를 들어 각 임베딩 벡터에 포지셔널 인코딩의 값을 더하면 같은 단어라고 하더라도 문장 내의 위치에 따라서 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라집니다.<br>\n",
    "<br>\n",
    "이에 따라 트랜스포머의 입력은 순서정보가 고려된 임베딩 벡터가 됩니다. 이를 코드로 구현하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179727c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "        \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        \n",
    "        # 배열의 짝수 인덱스 (2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        \n",
    "        # 배열의 홀수 인덱스 (2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        \n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2aee8d",
   "metadata": {},
   "source": [
    "50 x 128의 크기를 가지는 포지셔널 인코딩 행렬을 시각화하여 어떤 형태를 가지는지 확인해봅시다.<br>\n",
    "이는 입력 문장의 단어가 50개이면서, 각 단어가 128차원의 임베딩 벡터를 가질 때 사용할 수 있는 행렬입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b556cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e060a",
   "metadata": {},
   "source": [
    "## 5. 어텐션(Attention)\n",
    "트랜스포머에서 사용되는 세 가지의 어텐션에 대해서 간단히 정리해봅시다. 지금은 큰 그림을 이해하는 것에만 집중합니다.<br>\n",
    "![](https://wikidocs.net/images/page/31379/attention.PNG)\n",
    "첫번째 그림인 셀프 어텐션은 인코더에서 이루어지지만, 두번째 그림인 셀프 어텐션과 세번째 그림인 인코더-디코더 어텐션은 디코더에서 이루어집니다.<br>\n",
    "<br>\n",
    "셀프 어텐션은 본질적으로 Query, Key, Value가 동일한 경우를 말합니다. <br>\n",
    "반면, 세번째 그림 인코더-디코더 어텐션에서는 Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터이므로 셀프 어텐션이라고 부르지 않습니다.<br>\n",
    "<br>\n",
    "* 주의할 점은 여기서 Query, Key 등이 같다는 것은 벡터의 값이 같다는 것이 아니라 벡터의 출처가 같다는 의미입니다.<br>\n",
    "\n",
    "<br>정리하면 다음과 같습니다.\n",
    "```\n",
    "인코더의 셀프 어텐션 : Query = Key = Value\n",
    "디코더의 마스크드 셀프 어텐션 : Query = Key = Value\n",
    "디코더의 인코더-디코더 어텐션 : Query : 디코더 벡터 / Key = Value : 인코더 벡터\n",
    "```\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer_attention_overview.PNG)\n",
    "<br>\n",
    "위 그림은 트랜스포머의 아키텍처에서 세가지 어텐션이 각각 어디에서 이루어지는지를 보여줍니다.<br>\n",
    "세 개의 어텐션에 추가적으로 '멀티 헤드'라는 이름이 붙어있습니다. 이는 트랜스포머가 어텐션을 병렬적으로 수행하는 방법을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27902a27",
   "metadata": {},
   "source": [
    "## 6. 인코더(Encoder)\n",
    "<br>\n",
    "인코더의 구조에 대해서 알아보겠습니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer9_final_ver.PNG)\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 $\\text{num_layers}$ 개수의 인코더 층을 쌓습니다.<br>\n",
    "논문에서는 총 6개의 인코더 층을 사용하였습니다. 인코더를 하나의 층이라는 개념으로 생각한다면, 하나의 인코더 층은 크게 총 2개의 서브층(sublayer)으로 나뉘어집니다.<br>\n",
    "<br>\n",
    "셀프 어텐션과 피드 포워드 신경망입니다. 위의 그림에서는 멀티 헤드 셀프 어텐션과 포지션 와이즈 피드 포워드 신경망이라고 적혀있지만, <br>\n",
    "멀티 헤드 셀프 어텐션은 셀프 어텐션을 병렬적으로 사용하였다는 의미고, 포지션 와이즈 피드 포워드 신경망은 우리가 알고있는 일반적인 피드 포워드 신경망입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf6a8e",
   "metadata": {},
   "source": [
    "## 7. 인코더의 셀프 어텐션\n",
    "<br>\n",
    "트랜스포머에서는 셀프 어텐션이라는 어텐션 기법이 등장하는데 앞서 배웠던 어텐션 함수에 대해서 복습하고, 셀프 어텐션이 앞서 배웠던 어텐션과 무엇이 다른지 알아보겠습니다.<br>\n",
    "<br>\n",
    "### 1) 셀프 어텐션의 의미와 이점\n",
    "<br>\n",
    "어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다. 그리고 구해낸 이 유사도를 가중치로 하여 키와 맵핑되어있는 각각의 '값(Value)'에 반영해줍니다.<br>\n",
    "<br>\n",
    "\n",
    "그리고 유사도가 반영된 '값(Value)'을 모두 가중합하여 리턴합니다.\n",
    "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)\n",
    "<br>\n",
    "여기까지는 앞서 배운 어텐션의 개념입니다. 그런데 어텐션 중에서는 셀프 어텐션(self-attention)이라는 것이 있습니다. <br>\n",
    "<br>\n",
    "어텐션을 자기 자신에게 수행한다는 의미입니다. 앞서 배운 seq2seq에서 어텐션을 사용할 경우의 Q, K, V의 정의를 다시 생각해봅시다.\n",
    "<br>\n",
    "```\n",
    "Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```\n",
    "<br>\n",
    "사실 t 시점이라는 것은 계속 변화하면서 반복적으로 쿼리를 수행하므로 결국 전체 시점에 대해서 일반화를 할 수도 있습니다.<br>\n",
    "<br>\n",
    "\n",
    "```\n",
    "Q = Querys : 모든 시점의 디코더 셀에서의 은닉 상태들\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```\n",
    "\n",
    "이처럼 기존에는 디코더 셀의 은닉 상태가 Q이고 인코더 셀의 은닉 상태가 K라는 점에서 Q와 K가 서로 다른 값을 가지고 있었습니다.<br>\n",
    "<br>\n",
    "그런데 셀프 어텐션에서는 Q, K, V가 전부 동일합니다. 트랜스포머의 셀프 어텐션에서의 Q, K, V는 아래와 같습니다.<br>\n",
    "<br>\n",
    "\n",
    "```\n",
    "Q : 입력 문장의 모든 단어 벡터들\n",
    "K : 입력 문장의 모든 단어 벡터들\n",
    "V : 입력 문장의 모든 단어 벡터들\n",
    "```\n",
    "\n",
    "셀프 어텐션에 대한 구체적인 사항을 배우기 전에 셀프 어텐션을 통해 얻을 수 있는 대표적인 효과에 대해서 이해해봅시다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer10.png)\n",
    "\n",
    "<br>\n",
    "위의 그림은 트랜스포머에 대한 구글 AI 블로그 포스트에서 가져왔습니다. <br>\n",
    "<br>\n",
    "위의 예시 문장을 번역하면 '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.' 라는 의미가 됩니다. <br>\n",
    "<br>\n",
    "그런데 여기서 그것(it)에 해당하는 것은 과연 길(street)일까요? 동물(animal)일까요? 우리는 피곤한 주체가 동물이라는 것을 아주 쉽게 알 수 있지만 기계는 그렇지 않습니다. <br>\n",
    "<br>\n",
    "하지만 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하므로서 그것(it)이 동물(animal)과 연관되었을 확률이 높다는 것을 찾아냅니다.<br>\n",
    "<br>\n",
    "트랜스포머에서의 셀프 어텐션의 동작 메커니즘을 알아봅시다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39208af",
   "metadata": {},
   "source": [
    "### 2) Q, K, V 벡터 얻기\n",
    "<br>\n",
    "앞서 셀프 어텐션은 입력 문장의 단어 벡터들을 가지고 수행한다고 하였는데, 사실 셀프 어텐션은 인코더의 초기 입력인 $d_{model}$의 차원을 가지는 단어 벡터들을 사용하여 셀프 어텐션을 수행하는 것이 아니라<br>\n",
    "우선 각 단어 벡터들로부터 Q벡터, K벡터, V벡터를 얻는 작업을 거칩니다.<br>\n",
    "<br>\n",
    "이때 이 Q벡터, K벡터, V벡터들은 초기 입력인 $d_{model}$의 차원을 가지는 단어 벡터들보다 더 작은 차원을 가지는데, <br>\n",
    "논문에서는 $d_{model} = 512$의 차원을 가졌던 각 단어 벡터들을 64의 차원을 가지는 Q벡터, K벡터, V벡터로 변환하였습니다.<br>\n",
    "<br>\n",
    "64라는 값은 트랜스포머의 또 다른 하이퍼파라미터인 $\\text{num_heads}$로 인해 결정되는데, 트랜스포머는 $d_{model}$을 $\\text{num_heads}$로 나눈 값을 각 Q벡터, K벡터, V벡터의 차원으로 결정합니다.<br>\n",
    "<br>\n",
    "논문에서는 $\\text{num_heads}$를 8로 하였습니다. 그림을 통해 이해해봅시다.<br>\n",
    "<br>\n",
    "예를 들어 여기서 사용하고 있는 예문 중 student라는 단어 벡터를 Q, K, V의 벡터로 변환하는 과정을 보겠습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer11.PNG)\n",
    "<br>\n",
    "기존의 벡터로부터 더 작은 벡터는 가중치 행렬을 곱하므로서 완성됩니다. 각 가중치 행렬은 $d_{model} × (d_{model}\\text{/num_heads})$의 크기를 가집니다.<br>\n",
    "<br>\n",
    "이 가중치 행렬은 훈련 과정에서 학습됩니다. 즉, 논문과 같이 $d_{model}=512$이고 $\\text{num_heads}=8$라면, 각 벡터에 3개의 서로 다른 가중치 행렬을 곱하고 64의 크기를 가지는 Q, K, V 벡터를 얻어냅니다.<br>\n",
    "<br>\n",
    "위의 그림은 단어 벡터 중 student벡터로부터 Q, K, V벡터를 얻어내는 모습을 보여줍니다. 모든 단어 벡터에 위와 같은 과정을 거치면 I, am, a, student는 각각의 Q, K, V벡터를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a73985",
   "metadata": {},
   "source": [
    "### 3) 스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)\n",
    "<br>\n",
    "Q, K, V벡터를 얻었다면 지금부터는 기존에 배운 어텐션 메커니즘과 동일합니다.<br>\n",
    "각 Q벡터는 모든 K벡터에 대해서 어텐션 스코어를 구하고 어텐션 분포를 구한 뒤에 이를 사용하여 모든 V벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구하게 됩니다.<br>\n",
    "그리고 이를 모든 Q벡터에 대해서 반복합니다.<br>\n",
    "<br>\n",
    "그런데 앞서 어텐션 챕터에서 어텐션 함수의 종류는 다양하다고 언급한 바 있습니다. <br>\n",
    "<br>\n",
    "트랜스포머에서는 내적만을 사용하는 어텐션 함수 $score(q, k)=q⋅k$가 아니라 여기에 특정값으로 나눠준 어텐션 함수인 $score(q, k)=q⋅k/\\sqrt{n}$를 사용합니다.<br>\n",
    "<br>\n",
    "이러한 함수를 사용하는 어텐션을 닷-프로덕트 어텐션(dot-product attention)에서 값을 스케일링하는 것을 추가하였다고 하여\n",
    "\n",
    "**스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)**이라고 합니다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer13.PNG)\n",
    "<br>\n",
    "우선 단어 I에 대한 Q벡터를 기준으로 설명해보겠습니다. 지금부터 설명하는 과정은 am에 대한 Q벡터, a에 대한 Q벡터, student에 대한 Q벡터에 대해서도 모두 동일한 과정을 거칩니다. <br>\n",
    "<br>\n",
    "위의 그림은 단어 I에 대한 Q벡터가 모든 K벡터에 대해서 어텐션 스코어를 구하는 것을 보여줍니다. 위의 128과 32는 저자가 임의로 가정한 수치로 신경쓰지 않아도 좋습니다.<br>\n",
    "<br>\n",
    "위의 그림에서 어텐션 스코어는 각각 단어 I가 단어 I, am, a, student와 얼마나 연관되어 있는지를 보여주는 수치입니다. <br>\n",
    "<br>\n",
    "트랜스포머에서는 두 벡터의 내적값을 스케일링하는 값으로 K벡터의 차원을 나타내는 $d_{k}$에 루트를 씌운 $\\sqrt{d_{k}}$ 사용하는 것을 택했습니다.<br>\n",
    "<br>\n",
    "앞서 언급하였듯이 논문에서 $d_{k}$는 $d_{model}\\text{/num_heads}$라는 식에 따라서 64의 값을 가지므로 $\\sqrt{d_{k}}$ 는 8의 값을 가집니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer14_final.PNG)\n",
    "\n",
    "이제 어텐션 스코어에 소프트맥스 함수를 사용하여 어텐션 분포(Attention Distribution)을 구하고, 각 V벡터와 가중합하여 어텐션값(Attention Value)을 구합니다. <br>\n",
    "<br>\n",
    "이를 단어 I에 대한 어텐션 값 또는 단어 I에 대한 컨텍스트 벡터(context vector)라고도 할 수 있습니다. <br>\n",
    "<br>\n",
    "am에 대한 Q벡터, a에 대한 Q벡터, student에 대한 Q벡터에 대해서도 모두 동일한 과정을 반복하여 각각에 대한 어텐션 값을 구합니다.<br>\n",
    "<br>\n",
    "그런데 한가지 의문이 생깁니다. 굳이 각 Q벡터마다 일일히 따로 연산할 필요가 있을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23fca9",
   "metadata": {},
   "source": [
    "### 4) 행렬 연산으로 일괄 처리하기\n",
    "사실 각 단어에 대한 Q, K, V 벡터를 구하고 스케일드 닷-프로덕트 어텐션을 수행하였던 위의 과정들은 벡터 연산이 아니라 행렬연산을 사용하면 일괄 계산이 가능합니다. <br>\n",
    "<br>\n",
    "지금까지 벡터 연산으로 설명하였던 이유는 이해를 돕기 위한 과정이고 실제로는 행렬 연산으로 구현됩니다.<br>\n",
    "<br>\n",
    "위의 과정을 벡터가 아닌 행렬 연산으로 이해해봅시다. 우선, 각 단어 벡터마다 일일히 가중치 행렬을 곱하는 것이 아니라 문장 행렬에 가중치 행렬을 곱하여 Q행렬, K행렬, V행렬을 구합니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer12.PNG)\n",
    "\n",
    "행렬 연산을 통해 어텐션 스코어는 어떻게 구할 수 있을까요?<br>\n",
    "<br>\n",
    "여기서 Q행렬을 K행렬을 전치한 행렬과 곱해준다고 해봅시다. 이렇게 되면 각각의 단어의 Q벡터와 K벡터의 내적이 각 행렬의 원소가 되는 행렬이 결과로 나옵니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer15.PNG)\n",
    "\n",
    "다시 말해 위의 그림의 결과 행렬의 값에 전체적으로 $\\sqrt{d_{k}}$를 나누어주면 이는 각 행과 열이 어텐션 스코어 값을 가지는 행렬이 됩니다.<br>\n",
    "<br>\n",
    "예를 들어 I행과 student열의 값은 I의 Q벡터와 student의 K벡터의 어텐션 스코어 값입니다. 위 행렬을 어텐션 스코어 행렬이라 합시다.<br>\n",
    "<br>\n",
    "어텐션 스코어 행렬을 구하였다면 남은 것은 어텐션 분포를 구하고 이를 사용하여 모든 단어에 대한 어텐션 값을 구하는 일입니다.<br>\n",
    "<br>\n",
    "이는 간단하게 어텐션 스코어 행렬에 소프트맥스 함수를 사용하고 V행렬을 곱하는 것으로 해결됩니다.<br>\n",
    "<br>\n",
    "이렇게 되면 각 단어의 어텐션 값을 모두 가지는 어텐션 값 행렬이 결과로 나옵니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer16.PNG)\n",
    "\n",
    "위의 그림은 행렬 연산을 통해 모든 값이 일괄 계산되는 과정을 식으로 보여줍니다. <br>\n",
    "<br>\n",
    "해당 식은 실제 트랜스포머 논문에 기재된 아래 수식과 정확하게 일치하는 식입니다.<br>\n",
    "<br>\n",
    "$Attention(Q, K, V) = softmax({QK^T\\over{\\sqrt{d_k}}})V$\n",
    "<br>\n",
    "위의 행렬 연산에 사용된 행렬의 크기를 모두 정리해봅시다. <br>\n",
    "<br>\n",
    "우선 입력 문장의 길이를 seq_len이라고 해봅시다. 그렇다면 문장행렬의 크기는 $(\\text{seq_len},\\ d_{model})$입니다.<br>\n",
    "<br>\n",
    "여기에 3개의 가중치 행렬을 곱해서 Q, K, V행렬을 만들어야 합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "우선 행렬의 크기를 정의하기 위해 행렬의 각 행에 해당되는 Q벡터와 K벡터의 차원을 $d_{k}$라고 하고, V벡터의 차원을 $d_{v}$라고 해봅시다.<br>\n",
    "<br>\n",
    "그렇다면 Q행렬과 K행렬의 크기는 $(\\text{seq_len},\\ d_{k})$이며 V행렬의 크기는 $(\\text{seq_len},\\ d_{v})$가 되어야 합니다. <br>\n",
    "<br>\n",
    "그렇다면 문장 행렬과 Q, K, V 행렬의 크기로부터 가중치 행렬의 크기 추정이 가능합니다. <br>\n",
    "<br>\n",
    "$W^{Q}$와 $W^{K}$는 $(d_{model},\\ d_{k})$의 크기를 가지며, $W^{V}$는 $(d_{model},\\ d_{v})$의 크기를 가집니다. 단, 논문에서는 $d_{k}$와 $d_{v}$의 차원은 $d_{model}\\text{/num_heads}$와 같습니다.<br>\n",
    "<br>\n",
    "즉, $d_{model}\\text{/num_heads}= d_{k}=d_{v}$입니다.<br>\n",
    "<br>\n",
    "결과적으로 $softmax({QK^T\\over{\\sqrt{d_k}}})V$식을 적용하여 나오는 어텐션 값 행렬 $a$의 크기는 $(\\text{seq_len},\\ d_{v})$이 됩니다.<br>\n",
    "<br>\n",
    "코드로 작성하면 아래와 같습니다.\n",
    "<br>\n",
    "<br>\n",
    "### 5) 스케일드 닷-프로덕트 어텐션 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1676aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장길이)\n",
    "    \n",
    "    # Q와 K의 곱. djxpstus tmzhdj godfuf.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "        \n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    #  attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=1)\n",
    "    \n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e230f",
   "metadata": {},
   "source": [
    "Q행렬과 K행렬을 전치한 행렬을 곱하고, 소프트맥스 함수를 사용하여 어텐션 분포 행렬을 얻은 뒤에 V행렬과 곱합니다. 코드에서 mask가 사용되는 if문은 아직 배우지 않은 내용으로 지금은 무시합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "scaled_dot_product_attention 함수가 정상 작동하는지 테스트를 해보겠습니다.<br>\n",
    "<br>\n",
    "우선 temp_q, temp_k, temp_v라는 임의의 Query, Key, Value행렬을 만들고 이를 scaled_dot_product_attention 함수에 입력으로 넣어 함수가 리턴하는 값을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c4beb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[    1,0],\n",
    "                      [   10,0],\n",
    "                      [  100,5],\n",
    "                      [ 1000,6]], dtype=tf.float32) # (3, 2)\n",
    "\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32) # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed1b04",
   "metadata": {},
   "source": [
    "여기서 주목할 점은 Query에 해당하는 temp_q의 값 [0, 10, 0]은 Key에 해당하는 temp_k의 두번째 값 [0, 10, 0]과 일치한다는 점입니다. <br>\n",
    "그렇다면 어텐션 분포와 어텐션 값은 과연 어떤 값이 나올까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efa1aea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6fb8f3",
   "metadata": {},
   "source": [
    "Query는 4개의 Key값 중 두번째 값과 일치하므로 어텐션 분포는 [0, 1, 0, 0]의 값을 가지며 결과적으로 Value의 두번째 값인 [10, 0]이 출력되는 것을 확인할 수 있습니다. 이번에는 Query의 다른 값으로 바꿔보고 함수를 실행해봅시다.<br>\n",
    "<br>\n",
    "이번에 사용할 Query값 [0, 0, 10]은 Key의 세번째 값과 네번째 값 두 개의 값 모두와 일치하는 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94af1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out , temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn)  # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out)   # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3604faa",
   "metadata": {},
   "source": [
    "Query의 값은 Key의 세번째 값과 네번째 값 두 개의 값과 모두 유사하다는 의미에서 어텐션 분포는 [0, 0, 0.5, 0.5]의 값을 가집니다.<br>\n",
    "<br>\n",
    "결과적으로 나오는 값 [550, 5.5]는 Value의 세번째 값 [100, 5]에 0.5를 곱한 값과 네번째 값 [1000, 6]에 0.5를 곱한 값의 원소별 합입니다.<br>\n",
    "<br>\n",
    "이번에는 하나가 아닌 3개의 Query의 값을 함수의 입력으로 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73aeec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn)  # 어텐션의 분포(어텐션 가중치의 나열)\n",
    "print(temp_out)   # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e03f3",
   "metadata": {},
   "source": [
    "### 6) 멀티 헤드 어텐션(Multi-head Attention)\n",
    "<br>\n",
    "앞서 배운 어텐션에서는 $d_{model}$의 차원을 가진 단어 벡터를 $\\text{num_heads}$로 나눈 차원을 가지는 Q, K, V벡터로 바꾸고 어텐션을 수행하였습니다.<br>\n",
    "<br>\n",
    "논문 기준으로는 512의 차원의 각 단어 벡터를 8로 나누어 64차원의 Q, K, V벡터로 바꾸어서 어텐션을 수행한 셈인데, <br>\n",
    "이제 $\\text{num_heads}$의 의미와 왜 $d_{model}$의 차원을 가진 단어 텍터를 가지고 어텐션을 하지않고 차원을 축소시킨 벡터로 어텐션을 수행하였는지 이해해보겠습니다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer17.PNG)\n",
    "\n",
    "<br>\n",
    "트랜스포머 연구진은 한번의 어텐션을 하는 것보다 여러번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단하였습니다.<br>\n",
    "<br>\n",
    "그래서 $d_{model}$의 차원을 $\\text{num_heads}$개로 나누어 $d_{model}\\text{/num_heads}$의 차원을 가지는 Q, K, V에 대해서 $\\text{num_heads}$개의 병렬 어텐션을 수행합니다.<br>\n",
    "<br>\n",
    "논문에서는 하이퍼파라미터인 $\\text{num_heads}$의 값을 8로 지정하였고, 8개의 병렬 어텐션이 이루어지게 됩니다.<br>\n",
    "<br>\n",
    "다시 말해 위에서 설명한 어텐션이 8개로 병렬로 이루어지게 되는데, 이때 각각의 어텐션 값 행렬을 어텐션 헤드라고 부릅니다.<br>\n",
    "<br>\n",
    "이때 가중치 행렬 $W^{Q}, W^{K}, W^{V}$의 값은 8개의 어텐션 헤드마다 전부 다릅니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "멀티 헤드 어텐션으로 얻을 수 있는 효과? 어텐션을 병렬로 수행하여 각각 다른 시각으로 정보를 수집하겠다는 것<br>\n",
    "ex) 케르베로스, 히드라와 같이 머리가 여러개면 시야가 넓듯<br>\n",
    "<br>\n",
    "<br>\n",
    "예를 들어 '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.'에서 단어 그것(it)이 쿼리였다고 가정하자.<br>\n",
    "<br>\n",
    "즉, it에 대한 Q벡터로부터 다른 단어와의 연관도를 구하였을 때 첫번째 어텐션 헤드는 '그것(it)'과 '동물(animal)'의 연관도를 높게 본다면, <br>\n",
    "두번째 어텐션헤드는 '그것(it)'과 '피곤하였기 때문이다(tired)'의 연관도를 높게 볼 수 있습니다.<br>\n",
    "이는 각 어텐션 헤드는 전부 다른 시각에서 보고있기 때문입니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer18_final.PNG)\n",
    "\n",
    "<br>\n",
    "병렬 어텐션을 모두 수행하였다면 모든 어텐션 헤드를 연결(concatenate)합니다.<br>\n",
    "모두 연결된 어텐션 헤드 행렬의 크기는 $(\\text{seq_len},\\ d_{model})$가 됩니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "지금까지의 그림에서는 4차원을 $d_{model}=512$로 표현하고, 2차원을 $d_{v}=64$로 표현해왔기 때문에 위의 그림의 행렬의 크기에 혼동이 있을 수 있으나 <br>\n",
    "8개의 어텐션 헤드의 연결(concatenate)과정의 이해를 위해 이번 행렬만 예외로 위와 같이 $d_{model}$의 크기를 $d_{v}$의 8배인 16차원으로 표현하였습니다.<br>\n",
    "아래의 그림에서는 다시 $d_{model}$를 4차원으로 표현합니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer19.PNG)\n",
    "\n",
    "어텐션 헤드를 모두 연결한 행렬은 또 다른 가중치 행렬 $W^{O}$을 곱하게 되는데, 이렇게 나온 결과 행렬이 멀티-헤드 어텐션의 최종결과물입니다.<br>\n",
    "<br>\n",
    "\n",
    "위의 그림은 어텐션 헤드를 모두 연결한 행렬이 가중치 행렬 $W^{O}$과 곱해지는 과정을 보여줍니다. <br>\n",
    "<br>\n",
    "이때 결과물인 멀티-헤드 어텐션 행렬은 인코더의 입력이었던 문장 행렬의 $(\\text{seq_len},\\ d_{model})$크기와 동일합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "다시 말해 인코더의 첫번째 서브층인 멀티-헤드 어텐션 단계를 끝마쳤을 때, 인코더의 입력으로 들어왔던 행렬의 크기가 아직 유지되고 있음을 기억해둡시다.<br>\n",
    "<br>\n",
    "첫번째 서브층인 멀티-헤드 어텐션과 두번째 서브층인 포지션 와이즈 피드 포워드 신경망을 지나면서 인코더의 입력으로 들어올 때의 행렬의 크기는 계속 유지되어야 합니다.<br>\n",
    "<br>\n",
    "트랜스포머는 동일한 구조의 인코더를 쌓은 구조입니다. 논문 기준으로는 인코더가 총 6개입니다. <br>\n",
    "<br>\n",
    "인코더에서의 입력의 크기가 출력에서도 동일 크기로 계속 유지되어야만 다음 인코더에서도 다시 입력이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589df32",
   "metadata": {},
   "source": [
    "### 7) 멀티 헤드 어텐션(Multi-head Attention) 구현하기\n",
    "<br>\n",
    "멀티 헤드 어텐션에서는 크게 두 종류의 가중치 행렬이 나왔습니다. Q, K, V행렬을 만들기 위한 가중치 행렬인 $W^Q, W^K, W^V$행렬과 바로 어텐션 헤드들을 연결(concatenation) 후에 곱해주는 WO행렬입니다.<br>\n",
    "<br>\n",
    "가중치 행렬을 곱하는 것을 구현 상에서는 입력을 전결합층.<br>\n",
    "<br>\n",
    "즉, 밀집층(Dense layer)을 지나게 하여 구현합니다. 케라스 코드상으로 지금까지 사용해왔던 Dense()에 해당됩니다.\n",
    "\n",
    "```\n",
    "Dense(units)\n",
    "```\n",
    "\n",
    "멀티 헤드 어텐션의 구현은 크게 다섯가지 파트로 구성됩니다.\n",
    "<br><br><br>\n",
    "1. $W^Q, W^K, W^V$에 해당되는 $d_{model}$크기의 밀집층(Dense layer)을 지나게 한다.<br>\n",
    "2. 지정된 헤드 수($\\text{num_heads}$)만큼 나눈다.(split)<br>\n",
    "3. 스케일드 닷 프로덕트 어텐션<br>\n",
    "4. 나눠졌던 헤드들을 연결(concatenation)한다.<br>\n",
    "5. $W^O$에 해당하는 밀집층을 지나게 한다.<br>\n",
    "<br>\n",
    "이론으로 설명할 때보다 심플하게 구성되었는데 결국 근본적으로 동일한 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ebe7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        # d_model을 num_heads로 나눈 값\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "    # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape = (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        # 참고) 인코더(k, v) - 디코더)(q) 어텐션에서는 query길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                     (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bdd13",
   "metadata": {},
   "source": [
    "### 8) 패딩 마스트(Padding Mask)\n",
    "아직 설명하지 않은 내용이 있습니다. 앞서 구현한 스케일드 닷 프로덕트 어텐션 함수 내부를 보면 amsk라는 값을 인자로 받아서,<br>\n",
    "<br>\n",
    "이 mask값에다가 -1e9라는 아주 작은 음수값을 곱한 후 어텐션 스코어 행렬에 더해주고 있습니다. 이 연산의 정체는 무엇일까요?\n",
    "\n",
    "```python\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "... 중략 ...\n",
    "    logits += (mask * -1e9) # 어텐션 스코어 행렬인 logits에 mask*-1e9 값을 더해주고 있다.\n",
    "... 중략 ...\n",
    "```\n",
    "\n",
    "이는 입력 문장에 $\\text{<PAD>}$토큰이 있을 경우 어텐션에서 사실상 제외하기 위한 연산입니다.<br>\n",
    "<br>\n",
    "예를 들어 $\\text{<PAD>}$가 포함된 입력 문장의 셀프 어텐션의 예제를 봅시다. <br>\n",
    "<br>\n",
    "이에 대해서 어텐션을 수행하고 어텐션 스코어 행렬을 얻는 과정은 다음과 같습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/pad_masking11.PNG)\n",
    "\n",
    "그런데 사실 단어 $\\text{<PAD>}$의 경우에는 실질적인 의미를 가진 단어가 아닙니다. 그래서 트랜스포머에서는 Key의 경우에 $\\text{<PAD>}$토큰이 존재한다면 이에 대해서는 유사도를 구하지 않도록 마스킹(Masking)을 해주기로 했습니다.<br>\n",
    "<br>\n",
    "여기서 마스킹이란 어텐션에서 제외하기 위해 값을 가린다는 의미입니다. <br>\n",
    "<br>\n",
    "어텐션 스코어 행렬에서 행에 해당하는 문장은 Query이고, 열에 해당하는 문장은 Key입니다. 그리고 Key에 $\\text{<PAD>}$가 있는 경우에는 해당 열 전체를 마스킹 해줍니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/pad_masking2.PNG)\n",
    "\n",
    "마스킹하는 방법은 어텐션 스코어 행렬의 마스킹 위치에 매우 작은 음수값을 넣어주는 것입니다.<br>\n",
    "<br>\n",
    "여기서 매우 작은 음수값이 라는 것은 -1,000,000,000과 같은 마이너스 무한대에 가까운 수라는 의미입니다. 현재 어텐션 스코어 함수는 소프트맥스 함수를 지나지 않은 상태입니다.<br>\n",
    "<br>\n",
    "앞서 배운 연산 순서라면 어텐션 스코어 함수는 소프트맥스 함수를 지나고, 그 후 Value행렬과 곱해지게 됩니다.<br>\n",
    "<br>\n",
    "그런데 현재 마스킹 위치에 매우 작은 음수 값이 들어가 있으므로 어텐션 스코어 행렬이 스프트맥스 함수를 지난 후에는 해당 위치값은 0이 되어 단어 간 유사도를 구하는 일에 $\\text{<PAD>}$토큰이 반영되지 않게 됩니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/softmax.PNG)\n",
    "\n",
    "<br>\n",
    "위 그림은 소프트맥스 함수를 지난 후를 가정하고 있습니다. 소프트맥스 함수를 지나면 각 행의 어텐션 가중치의 총 합은 1이 되는데, 단어 $\\text{<PAD>}$의 경우에는 0이 되어 어떤 유의미한 값을 가지고 있지 않습니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "패딩 마스크를 구현하는 방법은 입력된 정수 시퀀스에서 패딩 토큰의 인덱스인지, 아닌지를 판별하는 함수를 구현하는 것입니다.<br>\n",
    "아래의 함수는 정수 시퀀스에서 0인 경우에는 1로 변환하고, 그렇지않은 경우에는 0으로 변환하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5eabb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c56ae6",
   "metadata": {},
   "source": [
    "임의의 정수 시퀀스 입력을 넣어서 어떻게 변환되는지 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de1a9e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb6b41",
   "metadata": {},
   "source": [
    "위 벡터를 통해서 1의 값을 가진 위치의 열을 어텐션 스코어 행렬에서 마스킹하는 용도로 사용할 수 있습니다. <br>\n",
    "위 벡터를 스케일드 닷 프로덕트 어텐션의 인자로 전달하면, 스케일드 닷 프로덕트 어텐션에서는 위 벡터에다가 매우 작은 음수값인 -1e9를 곱하고, 이를 행렬에 더해주어 해당 열을 전부 마스킹합니다.<br>\n",
    "<br>\n",
    "첫번째 서브층인 멀티 헤드 어텐션을 구현해보았습니다. <br>\n",
    "앞서 인코더는 두 개의 서브 서브층(sublayer)으로 나뉘어진다고 언급한 적이 있는데, 두번째 서브층인 포지션-와이즈 피드 포워드 신경망에 대해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be00f0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 8. 포지션-와이즈 피드 포워드 신경망(Position-wise FFNN)<br>\n",
    "<br>\n",
    "\n",
    "지금은 인코더를 설명하고 있지만, 포지션 와이즈 FFNN은 인코더와 디코더에서 공통적으로 가지고 있는 서브층입니다.<br>\n",
    "포지션 와이즈 FFNN는 쉽게 말하면 완전 연결 FFNN(Fully-connected FFNN)이라고 해석할 수 있습니다.<br>\n",
    "앞서 인공신경망은 결국 벡터와 행렬 연산으로 표현될 수 있음을 배웠습니다. 아래는 포지션 와이즈 FFNN의 수식을 보여줍니다.<br>\n",
    "<br>\n",
    "$FFNN(x) = MAX(0, x{W_{1}} + b_{1}){W_2} + b_2$<br>\n",
    "<br>\n",
    "식을 그림으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/positionwiseffnn.PNG)\n",
    "\n",
    "여기서 $x$는 앞서 멀티 헤드 어텐션의 결과로 나온 $(\\text{seq_len},\\ d_{model})$의 크기를 가지는 행렬을 말합니다.<br>\n",
    "가중치 행렬 $W_1$은 $(d_{model},\\ d_{ff})$의 크기를 가지고 가중치 행렬 $W_2$은 $(d_{ff},\\ d_{model})$의 크기를 가집니다.<br>\n",
    "논문에서 은닉층의 크기인 $d_{ff}$는 앞서 하이퍼파라미터를 정의할 때 언급했듯이 2,048의 크기를 가집니다.<br>\n",
    "<br>\n",
    "여기서 매개변수 $W_1, b_{1}, W_2, b_2$는 하나의 인코더 층 내에서는 다른 문장, 다른 단어들마다 정확하게 동일하게 사용됩니다.<br>\n",
    "하지만 인코더 층마다는 다른 값을 가집니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer20.PNG)\n",
    "\n",
    "위의 그림에서 좌측은 인코더의 입력을 벡터 단위로 봤을 때, 각 벡터들이 멀티 헤드 어텐션 층이라는 인코더 내 첫번째 서브 층을 지나 FFNN을 통과하는 것을 보여줍니다.<br>\n",
    "<br>\n",
    "이는 두번째 서브층인 Position-wise FFNN을 의미합니다. 물론, 실제로는 그림 우측과 같이 행렬로 연산되는데, 두번째 서브층을 지난 인코더의 최종 출력은 여전히 인코더의 입력의 크기였던 $(\\text{seq_len},\\ d_{model})$의 크기가 보존되고 있습니다.<br>\n",
    "<br>\n",
    "하나의 인코더 층을 지난 이 행렬은 다음 인코더 층으로 전달되고, 다음 층에서도 동일한 인코더 연산이 반복됩니다.<br>\n",
    "<br>\n",
    "이를 구현하면 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "# 다음의 코드는 인코더와 디코더 내부에서 사용할 예정입니다.\n",
    "outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d9a50",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 9. 잔차 연결(Residual connection)과 층 정규화(Layer Normalization)\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer21.PNG)\n",
    "\n",
    "인코더의 두 개의 서브층에 대해서 이해하였다면 인코더에 대한 설명은 거의 끝났습니다.<br>\n",
    "트랜스포머에서는 이러한 두 개의 서브층을 가진 인코더에 추가적으로 사용하는 기법이 있는데, 바로 Add & Norm입니다. <br>\n",
    "더 정확히는 잔차 연결(residual connection)과 층 정규화(layer normalization)를 의미합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "### 1) 잔차 연결(Residual connection)\n",
    "<br>\n",
    "잔차 연결(residual connection)의 의미를 이해하기 위해서 어떤 함수 $H(x)$에 대한 이야기를 해보겠습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer22.PNG)\n",
    "\n",
    "위 그림은 입력 $x$와 $x$에 대한 어떤 함수 $F(x)$의 값을 더한 함수 $H(x)$의 구조를 보여줍니다. <br>\n",
    "<br>\n",
    "어떤 함수 $F(x)$가 트랜스포머에서는 서브층에 해당됩니다. 다시 말해 잔차 연결은 서브층의 입력과 출력을 더하는 것을 말합니다. <br>\n",
    "<br>\n",
    "앞서 언급했듯이 트랜스포머에서 서브층의 입력과 출력은 동일한 차원을 갖고 있으므로, 서브층의 입력과 서브층의 출력은 덧셈 연산을 할 수 있습니다. <br>\n",
    "<br>\n",
    "이것이 바로 위의 인코더 그림에서 각 화살표가 서브층의 입력에서 출력으로 향하도록 그려졌던 이유입니다. <br>\n",
    "잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습을 돕는 기법입니다.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "이를 식으로 표현하면 $x+Sublayer(x)$입니다.<br>\n",
    "<br>\n",
    "가령, 서브층이 멀티 헤드 어텐션이었다면 잔차 연결 연산은 다음과 같습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/residual_connection.PNG)\n",
    "\n",
    "위 그림은 멀티 헤드 어텐션의 입력과 멀티 헤드 어텐션의 결과가 더해지는 과정을 보여줍니다.<br>\n",
    "<br>\n",
    "관련 논문 : https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a62cd",
   "metadata": {},
   "source": [
    "### 2) 층 정규화(Layer Normalization)\n",
    "<br>\n",
    "잔차 연결을 거친 결과는 이어서 층 정규화 과정을 거치게됩니다. <br>\n",
    "잔차 연결의 입력을 $x$, 잔차 연결과 층 정규화 두 가지 연산을 모두 수행한 후의 결과 행렬을 $LN$이라고 하였을 때, 잔차 연결 후 층 정규화 연산을 수식으로 표현하자면 다음과 같습니다.<br>\n",
    "<br>\n",
    "$LN = LayerNorm(x+Sublayer(x))$\n",
    "<br>\n",
    "\n",
    "층 정규화를 하는 과정에 대해서 이해해보자. 층 정규화는 **텐서의 마지막 차원**에 대해서 평균과 분산을 구하고 이를 가지고 어떤 수식을 통해 값을 정규화하여 학습을 돕습니다. <br>\n",
    "\n",
    "\n",
    "여기서 텐서의 마지막 차원이란 것은 트랜스포머에서는 $d_{model}$차원을 의미합니다. 아래 그림은 $d_{model}$차원의 방향을 화살표로 표현하였습니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/layer_norm_new_1_final.PNG)\n",
    "\n",
    "<br>\n",
    "\n",
    "층 정규화를 위해서 우선, 화살표 방향으로 각각 평균 $μ$과 분산 $σ^{2}$을 구합니다. 각 화살표 방향의 벡터를 $x_{i}$라고 명명해봅시다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/layer_norm_new_2_final.PNG)\n",
    "\n",
    "<br>\n",
    "층 정규화를 수행한 후에는 $x_{i}$는 $ln_{i}$라는 벡터로 정규화가 됩니다.<br>\n",
    "<br>\n",
    "$ln_{i} = LayerNorm(x_{i})$\n",
    "<br>\n",
    "층 정규화의 수식을 알아봅시다. 여기서는 층 정규화를 두가지 과정으로 나누어 설명하겠습니다. <br>\n",
    "첫번째는 평균과 분산을 통한 정규화, 두번째는 감마와 베타를 도입하는 것입니다. 우선, 평균과 분산을 통해 벡터 $x_i$를 정규화해줍니다.<br>\n",
    "$x_i$는 벡터인 반면, 평균 $μ_i$과 분산 $σ^{2}_{i}$은 스칼라입니다.<br>\n",
    "벡터 $x_i$의 각 차원을 $k$라고 하였을 때, $x_{i,k}$는 다음의 수식과 같이 정규화 할 수 있습니다.<br>\n",
    "다시 말해 벡터 $x_i$의 각 $k$차원의 값이 다음과 같이 정규화 되는 것입니다.\n",
    "<br>\n",
    "$\\hat{x}_{i, k} = \\frac{x_{i, k}-μ_{i}}{\\sqrt{σ^{2}_{i}+\\epsilon}}$ <br>\n",
    "<br>\n",
    "$ϵ$(입실론)은 분모가 0이 되는 것을 방지하는 값입니다.<br>\n",
    "<br>\n",
    "이제 $γ$(감마)와 $β$(베타)라는 벡터를 준비합니다. 단, 이들의 초기값은 각각 1과 0입니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/%EA%B0%90%EB%A7%88%EB%B2%A0%ED%83%80.PNG)\n",
    "\n",
    "<br>\n",
    " $γ$와 $β$를 도입한 층 정규화의 최종 수식은 다음과 같으며  $γ$와 $β$는 학습가능한 파라미터입니다.<br>\n",
    " <br>\n",
    " $ln_{i} = γ\\hat{x}_{i}+β = LayerNorm(x_{i})$\n",
    " <br>\n",
    " \n",
    "관련 논문 : https://arxiv.org/pdf/1607.06450.pdf<br>\n",
    "<br>\n",
    "케라스에서는 층 정규화를 위한 LayerNormalization()를 제공하고 있으므로 이를 가져와 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126849dd",
   "metadata": {},
   "source": [
    "## 인코더 구현하기\n",
    "<br>\n",
    "지금까지 배운 내용을 바탕으로 인코더를 구현한 코드는 다음과 같습니다. 인코더의 입력으로 들어가는 문장에는 패딩이 있을 수 있으므로, 어텐션 시 패딩 토큰을 제외하도록 패딩 마스크를 사용합니다.<br>\n",
    "<br>\n",
    "이는 MultiHeadAttention 함수의 mask의 인자값으로 padding_mask가 사용되는 이유입니다.<br>\n",
    "인코더는 총 두개의 서브층으로 이루어지는데 멀티 헤드 어텐션과 피드 포워드 신경망입니다.<br>\n",
    "<br>\n",
    "각 서브층 이후에는 드롭 아웃, 잔차 연결과 층 정규화가 수행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e875bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name='inputs')\n",
    "    \n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query':inputs, 'key':inputs, 'value':inputs, # Q = K = V\n",
    "            'mask':padding_mask # 패딩 마스크 사용\n",
    "    })\n",
    "    \n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention  = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention  = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    # 드롭아웃 + 잔차 연결 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs = [inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c32c80",
   "metadata": {},
   "source": [
    "위 코드는 하나의 인코더 블록. <br>\n",
    "즉, 하나의 인코더 층을 구현하는 코드입니다. <br>\n",
    "실제로 트랜스포머는 num_layers 개수만큼의 인코더 층을 사용하므로 이를 여러번 쌓는 코드를 별도 구현해줄 필요가 있습니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "## 11. 인코더 쌓기\n",
    "<br>\n",
    "지금까지 인코더 층의 내부 아키텍처에 대해서 이해해보았습니다.<br>\n",
    "이러한 인코더 층을 num_layers개만큼 쌓고 마지막 인코더 층에서 얻는(seq_len, d_model)크기의 행렬을 디코더로 보내줌으로써 트랜스포머 인코더의 인코딩 연산이 끝나게 됩니다.<br>\n",
    "아래의 코드는 인코더 층을 num_layers개만큼 쌓는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1899215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='encoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    \n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "                                dropout=dropout, name='encoder_layer_{}'.format(i),\n",
    "                               )([outputs, padding_mask])\n",
    "        \n",
    "    return tf.keras.Model(\n",
    "        inputs = [inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89525d4",
   "metadata": {},
   "source": [
    "## 12. 인코더에서 디코더로(From Encoder To Decoder)\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer_from_encoder_to_decoder.PNG)\n",
    "\n",
    "<br>\n",
    "지금까지 인코더에 대해서 정리해보았습니다. 이렇게 구현된 인코더는 총 $\\text{num_layers}$만큼의 층 연산을 순차적으로 한 후에 마지막 층의 인코더의 출력을 디코더에게 전달합니다. <br>\n",
    "인코더 연산이 끝났으면 디코더 연산이 시작되어 디코더 또한 $\\text{num_layers}$만큼의 연산을 하는데, 이때마다 인코더가 보낸 출력을 각 디코더 층 연산에 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367e1c9",
   "metadata": {},
   "source": [
    "## 13. 디코더의 첫번째 서브층 : 셀프 어텐션과 룩-어헤드 마스크\n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/decoder.PNG)\n",
    "\n",
    "<br>\n",
    "위 그림과 같이 디코더도 인코더와 동일하게 임베딩 층과 포지셔널 인코딩을 거친 후의 문장 행렬이 입력됩니다. <br>\n",
    "트랜스포머 또한 seq2seq와 마찬가지로 교사 강요(Teacher Forcing)을 사용하여 훈련되므로 학습 과정에서 디코더는 번역할 문장에 해당되는 $\\text{<sos> je suis étudiant}$의 문장 행렬을 한 번에 입력받습니다.  <br>\n",
    "그리고 디코더는 이 문장 행렬로부터 각 시점의 단어를 예측하도록 훈련됩니다. <br>\n",
    " <br>\n",
    "여기서 문제가 있습니다. seq2seq의 디코더에 사용되는 RNN 계열의 신경망은 입력 단어를 매 시점마다 순차적으로 입력받으므로 다음 단어 예측에 현재 시점을 포함한 이전 시점에 입력된 단어들만 참고할 수 있습니다.  <br>\n",
    "반면, 트랜스포머는 문장 행렬로 입력을 한 번에 받으므로 현재 시점의 단어를 예측하고자 할 때, 입력 문장 행렬로부터 미래 시점의 단어까지도 참고할 수 있는 현상이 발생합니다.  <br>\n",
    "가령, $\\text{suis}$를 예측해야 하는 시점이라고 해봅시다.  <br>\n",
    "RNN 계열의 seq2seq의 디코더라면 현재까지 디코더에 입력된 단어는 $\\text{<sos>}$와 $\\text{je}$뿐일 것입니다. 반면, 트랜스포머는 이미 문장 행렬로 $\\text{<sos> je suis étudiant}$를 입력받았습니다.\n",
    "\n",
    "이를 위해 트랜스포머의 디코더에서는 현재 시점의 예측에서 현재 시점보다 미래에 있는 단어들을 참고하지 못하도록 룩-어헤드 마스크(look-ahead mask)를 도입했습니다. 직역하면 '미리보기에 대한 마스크'입니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/%EB%94%94%EC%BD%94%EB%8D%94.PNG)\n",
    "\n",
    "<br>\n",
    "룩-어헤드 마스크(look-ahead mask)는 디코더의 첫번째 서브층에서 이루어집니다. <br>\n",
    "디코더의 첫번째 서브층인 멀티 헤드 셀프 어텐션 층은 인코더의 첫번째 서브층인 멀티 헤드 셀프 어텐션 층과 동일한 연산을 수행합니다. <br>\n",
    "오직 다른 점은 어텐션 스코어 행렬에서 마스킹을 적용한다는 점만 다릅니다. <br>\n",
    "우선 다음과 같이 셀프 어텐션을 통해 어텐션 스코어 행렬을 얻습니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/decoder_attention_score_matrix.PNG)\n",
    "\n",
    "<br>\n",
    "이제 자기 자신보다 미래에 있는 단어들은 참고하지 못하도록 다음과 같이 마스킹합니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/%EB%A3%A9%EC%96%B4%ED%97%A4%EB%93%9C%EB%A7%88%EC%8A%A4%ED%81%AC.PNG)\n",
    "\n",
    "<br>\n",
    "마스킹 된 후의 어텐션 스코어 행렬의 각 행을 보면 자기 자신과 그 이전 단어들만을 참고할 수 있음을 볼 수 있습니다. <br>\n",
    "그 외에는 근본적으로 셀프 어텐션이라는 점과, 멀티 헤드 어텐션을 수행한다는 점에서 인코더의 첫번째 서브층과 같습니다.<br>\n",
    "<br>\n",
    "룩-어헤드 마스크의 구현에 대해 알아봅시다. <br>\n",
    "룩-어헤드 마스크는 패딩 마스크와 마찬가지로 앞서 구현한 스케일드 닷 프로덕트 어텐션 함수에 mask라는 인자로 전달됩니다.<br>\n",
    "패딩 마스킹을 써야하는 경우에는 스케일드 닷 프로덕트 어텐션 함수에 패딩 마스크를 전달하고, 룩-어헤드 마스킹을 써야하는 경우에는 스케일드 닷 프로덕트 어텐션 함수에 룩-어헤드 마스크를 전달합니다.<br>\n",
    "\n",
    "\n",
    "```python\n",
    "# 스케일드 닷 프로덕트 어텐션 함수를 다시 복습해봅시다.\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "... 중략 ...\n",
    "    logits += (mask * -1e9) # 어텐션 스코어 행렬인 logits에 mask*-1e9 값을 더해주고 있다.\n",
    "... 중략 ...\n",
    "```\n",
    "\n",
    "트랜스포머에는 총 세 가지 어텐션이 존재하며, 모두 멀티 헤드 어텐션을 수행하고, 멀티 헤드 어텐션 함수 내부에서 스케일드 닷 프로덕트 어텐션 함수를 호출하는데 각 어텐션 시 함수에 전달하는 마스킹은 다음과 같습니다.<br>\n",
    "<br>\n",
    "* 인코더의 셀프 어텐션 : 패딩 마스크를 전달<br>\n",
    "* 디코더의 첫번째 서브층인 마스크드 셀프 어텐션 : 룩-어헤드 마스크를 전달 <-- 지금 설명하고 있음.<br>\n",
    "* 디코더의 두번째 서브층인 인코더-디코더 어텐션 : 패딩 마스크를 전달<br>\n",
    "<br>\n",
    "<br>\n",
    "이때 룩-어헤드 마스크를 한다고해서 패딩 마스크가 불필요한 것이 아니므로 룩-어헤드 마스크는 패딩 마스크를 포함하도록 구현합니다. <br>\n",
    "룩-어헤드 마스크를 구현하는 방법은 패딩 마스크 때와 마찬가지로 마스킹을 하고자 하는 위치에는 1을, 마스킹을 하지 않는 위치에는 0을 리턴하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7a8fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd7fc2",
   "metadata": {},
   "source": [
    "임의의 정수 시퀀스 입력을 넣어서 결과를 봅시다. 패딩 마스크를 테스트 하기위해 세번째 위치에 정수 0을 넣었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b06574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e381c1",
   "metadata": {},
   "source": [
    "룩-어헤드 마스크이므로 삼각형 모양의 마스킹이 형성되면서 패딩 마스크가 포함되어져 있는 세번째 열이 마스킹됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb08ee",
   "metadata": {},
   "source": [
    "## 14. 디코더의 두번째 서브층 : 인코더-디코더 어텐션\n",
    "<br>\n",
    "디코더의 두번째 서브층에 대해서 이해해봅시다. <br>\n",
    "디코더의 두번째 서브층은 멀티 헤드 어텐션을 수행한다는 점에서는 이전의 어텐션들(인코더와 디코더의 첫번째 서브층)과는 공통점이 있으나 이번에는 셀프 어텐션이 아닙니다.<br>\n",
    "<br>\n",
    "셀프 어텐션은 Query, Key, Value가 같은 경우를 말하는데, 인코더-디코더 어텐션은 Query가 디코더인 행렬인 반면, Key와 Value는 인코더 행렬이기 때문입니다. <br>\n",
    "다시 한 번 각 서브층에서의 Q, K, V의 관계를 정리해봅시다.\n",
    "\n",
    "```\n",
    "인코더의 첫번째 서브층 : Query = Key = Value\n",
    "디코더의 첫번째 서브층 : Query = Key = Value\n",
    "디코더의 두번째 서브층 : Query : 디코더 행렬 / Key = Value : 인코더 행렬\n",
    "```\n",
    "디코더의 두번째 서브층을 확대해보면, 다음과 같이 인코더로부터 두 개의 화살표가 그려져 있습니다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/%EB%94%94%EC%BD%94%EB%8D%94%EB%91%90%EB%B2%88%EC%A7%B8%EC%84%9C%EB%B8%8C%EC%B8%B5.PNG)\n",
    "\n",
    "<br>\n",
    "두 개의 화살표는 각각 Key와 Value를 의미하며 이는 인코더의 마지막 층에서 온 행렬로부터 얻습니다. <br>\n",
    "반면 Query는 디코더의 첫번째 서브층의 결과 행렬로부터 얻는다는 점이 다릅니다. <br>\n",
    "Query가 디코더 행렬, Key가 인코더 행렬일 때, 어텐션 스코어 행렬을 구하는 과정은 다음과 같습니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/%EB%94%94%EC%BD%94%EB%8D%94%EB%91%90%EB%B2%88%EC%A7%B8%EC%84%9C%EB%B8%8C%EC%B8%B5%EC%9D%98%EC%96%B4%ED%85%90%EC%85%98%EC%8A%A4%EC%BD%94%EC%96%B4%ED%96%89%EB%A0%AC_final.PNG)\n",
    "\n",
    "<br>\n",
    "\n",
    "그 외에 멀티 헤드 어텐션을 수행하는 과정은 다른 어텐션들과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce015c",
   "metadata": {},
   "source": [
    "## 15. 디코더 구현하기\n",
    "<br>\n",
    "디코더는 총 세 개의 서브층으로 구성됩니다. <br>\n",
    "첫번째와 두번째 서브층 모두 멀티 헤드 어텐션이지만, 첫번째 서브층은 mask의 인자값으로 look_ahead_mask가 들어가는 반면, 두번째 서브층은 mask의 인자값으로 padding_mask가 들어가는 것을 확인할 수 있습니다. <br>\n",
    "이는 첫번째 서브층은 마스크드 셀프 어텐션을 수행하기 때문입니다.<br>\n",
    "세 개의 서브층 모두 서브층 연산 후에는 드롭 아웃, 잔차 연결, 층 정규화가 수행되는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2084a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 패딩 마스크(두번째 서브층)\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7dfae",
   "metadata": {},
   "source": [
    "인코더와 마찬가지로 디코더도 num_layers개만큼 쌓는 코드가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c97ab52",
   "metadata": {},
   "source": [
    "## 16. 디코더 쌓기\n",
    "포지셔널 인코딩 후 디코더 층을 num_layers의 개수만큼 쌓는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0cf8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "            )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd4567",
   "metadata": {},
   "source": [
    "## 17. 트랜스포머 구현하기\n",
    "<br>\n",
    "지금까지 구현한 인코더와 디코더 함수를 조합하여 트랜스포머를 조립할 차례입니다. <br>\n",
    "인코더의 출력은 디코더에서 인코더-디코더 어텐션에서 사용되기 위해 디코더로 전달해줍니다. <br>\n",
    "그리고 디코더의 끝단에는 다중 클래스 분류 문제를 풀 수 있도록, vocab_size 만큼의 뉴런을 가지는 출력층을 추가해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6fa4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d99ad0",
   "metadata": {},
   "source": [
    "## 18. 트랜스포머 하이퍼파라미터 정하기\n",
    "<br>\n",
    "트랜스포머의 하이퍼파라미터를 임의로 정하고 모델을 만들어봅시다. 현재 훈련 데이터가 존재하는 것은 아니지만, 단어 집합의 크기는 임의로 9,000으로 정합니다. <br>\n",
    "단어 집합의 크기로부터 룩업 테이블을 수행할 임베딩 테이블과 포지셔널 인코딩 행렬의 행의 크기를 결정할 수 있습니다.<br>\n",
    "<br>\n",
    "논문에서 제시한 것과는 다르게 하이퍼파라미터를 정해보겠습니다. <br>\n",
    "인코더와 디코더의 층의 개수 $\\text{num_layers}$는 4개, 인코더와 디코더의 포지션 와이즈 피드 포워드 신경망의 은닉층 $d_{ff}$은 128, <br>\n",
    "인코더와 디코더의 입, 출력의 차원 $d_{model}$은 128, 멀티-헤드 어텐션에서 병렬적으로 사용할 헤드의 수 $\\text{num_heads}$는 4로 정했습니다. <br>\n",
    "128/4의 값인 32가 $d_v$의 값이 되겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14d258af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1f733",
   "metadata": {},
   "source": [
    "## 19. 손실 함수 정의하기  \n",
    "   <br>\n",
    "다중 클래스 분류 문제를 풀 예정이므로 크로스 엔트로피 함수를 손실 함수로 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09dd502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ffaef",
   "metadata": {},
   "source": [
    "## 20. 학습률\n",
    "<br>\n",
    "학습률 스케줄러(Learning rate Scheduler)는 미리 학습 일정을 정해두고 그 일정에 따라 학습률이 조정되는 방법입니다. <br>\n",
    "트랜스포머의 경우 사용자가 정한 단계까지는 학습률을 증가시켰다가 단계에 이르면 학습률을 점차적으로 떨어트리는 방식을 사용합니다. <br>좀 더 구체적으로 봅시다. step_num(단계)이란 옵티마이저가 매개변수를 업데이트 하는 한 번의 진행 횟수를 의미합니다. <br>\n",
    "트랜스포머에서는 warmup_steps이라는 변수를 정하고 step_num이 warmup_steps보다 작을 경우는 학습률을 선형적으로 증가 시키고, step_num이 warmup_steps에 도달하게 되면 학습률을 step_num의 역제곱근에 따라서 감소시킵니다. <br>\n",
    "이를 식으로 표현하면 아래와 같습니다. <br>\n",
    "warmup_steps의 값으로는 4,000을 사용하였습니다.<br>\n",
    "<br>\n",
    "$\\Large{lrate = d_{model}^{-0.5} × min(\\text{step_num}^{-0.5},\\ \\text{step_num} × \\text{warmup_steps}^{-1.5})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2a9deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ad921",
   "metadata": {},
   "source": [
    "학습률의 변화를 시각화해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0388897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e255a",
   "metadata": {},
   "source": [
    "[논문에서는 언급되지 않은 트랜스포머의 구현 이야기 : https://tunz.kr/post/4](https://tunz.kr/post/4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70bf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
