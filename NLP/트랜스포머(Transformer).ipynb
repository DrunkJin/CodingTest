{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd81441",
   "metadata": {},
   "source": [
    "[출처 : https://wikidocs.net/31379](https://wikidocs.net/31379)\n",
    "# 1) 트랜스포머(Transformer)\n",
    "\n",
    "* 어텐션 메커니즘에 대한 이해가 필요함<br>\n",
    "<br>\n",
    "트랜스포머(Transformer)는 2017년 구글이 발표한 논문인 \"Attention is all you need\"에서 나온 모델로 기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델입니다.<br>\n",
    "<br>\n",
    "이 모델은 RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 번역 성능에서도 RNN보다 우수한 성능을 보여주었습니다.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70da8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c407a",
   "metadata": {},
   "source": [
    "## 1. 기존의 seq2seq 모델의 한계\n",
    "기존의 seq2seq를 상기해봅시다. <br>\n",
    "<br>\n",
    "기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어져 있었습니다. <br>\n",
    "<br>\n",
    "여기서 인코더는 입력 시퀀스를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해서 출력 시퀀스를 만들어냈습니다. <br>\n",
    "<br>\n",
    "하지만 이러한 구조는 인코더가 입력 시퀀스를 하나의 벡터로 압축하는 과정에서 입력 시퀀스의 정보가 일부 손실된다는 단점이 있었고, 이를 보정하기 위해 어텐션이 사용되었습니다. <br>\n",
    "<br>\n",
    "그런데 어텐션을 RNN의 보정을 위한 용도로서 사용하는 것이 아니라 어텐션만으로 인코더와 디코더를 만들어보면 어떨까요?\n",
    "<br>\n",
    "<br>\n",
    "## 2. 트랜스포머(Transformer)의 주요 하이퍼파라미터\n",
    "\n",
    "시작에 앞서 트랜스포머의 하이퍼파라미터를 정의합니다.<br>\n",
    "<br>\n",
    "각 하이퍼파라미터의 의미에 대해서는 뒤에서 설명하기로하고, 여기서는 트랜스포머에는 이러한 하이퍼파라미터가 존재한다는 정도로만 이해해보겠습니다. <br>\n",
    "<br>\n",
    "아래에서 정의하는 수치는 트랜스포머를 제안한 논문에서 사용한 수치로 하이퍼파라미터는 사용자가 모델 설계시 임의로 변경할 수 있는 값들입니다.<br>\n",
    "<br>\n",
    "$d_{model} = 512$ <br>\n",
    "<br>\n",
    "트랜스포머의 인코더와 디코더에서의 정해진 입력과 출력의 크기를 의미합니다. <br>\n",
    "<br>\n",
    "임베딩 벡터의 차원 또한 $d_{model}$이며, 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때에도 이 차원을 유지합니다. <br>\n",
    "<br>논문에서는 512입니다.<br>\n",
    "<br>\n",
    "$\\text{num_layers} = 6$<br>\n",
    "<br>\n",
    "트랜스포머에서 하나의 인코더와 디코더를 층으로 생각하였을 때, 트랜스포머 모델에서 인코더와 디코더가 총 몇 층으로 구성되었는지를 의미합니다. <br>\n",
    "<br>\n",
    "논문에서는 인코더와 디코더를 각각 총 6개 쌓았습니다.<br>\n",
    "<br>\n",
    "$\\text{num_heads} = 8$<br>\n",
    "<br>\n",
    "트랜스포머에서는 어텐션을 사용할 때, 한 번 하는 것 보다 여러 개로 분할해서 병렬로 어텐션을 수행하고 결과값을 다시 하나로 합치는 방식을 택했습니다. 이때 이 병렬의 개수를 의미합니다.<br>\n",
    "<br>\n",
    "$d_{ff} = 2048$\n",
    "<br>\n",
    "트랜스포머 내부에는 피드 포워드 신경망이 존재하며 해당 신경망의 은닉층의 크기를 의미합니다. 피드 포워드 신경망의 입력층과 출력층의 크기는 $d_{model}$입니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "## 3. 트랜스포머(Transformer)\n",
    "![](https://wikidocs.net/images/page/31379/transformer1.PNG)\n",
    "<br>\n",
    "트랜스포머는 RNN을 사용하지 않지만 기존의 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고, 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 유지하고 있습니다. <br>\n",
    "<br>\n",
    "이전 seq2seq 구조에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점(time step)을 가지는 구조였다면 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조입니다.<br>\n",
    "<br>트랜스포머를 제안한 논문에서는 인코더와 디코더의 개수를 각각 6개 사용하였습니다.<br>\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer2.PNG)\n",
    "위의 그림은 인코더와 디코더가 6개씩 존재하는 트랜스포머의 구조를 보여줍니다. <br>\n",
    "<br>\n",
    "인코더와 디코더가 각각 여러 개 쌓여있다는 의미를 사용할 때는 알파벳 s를 뒤에 붙여 encoders, decoders라고 표현하겠습니다.\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer4_final_final_final.PNG)\n",
    "위의 그림은 인코더로부터 정보를 전달받아 디코더가 출력 결과를 만들어내는 트랜스포머 구조를 보여줍니다.<br>\n",
    "<br>\n",
    "디코더는 마치 기존의 seq2seq 구조처럼 시작 심볼 $<sos>$를 입력으로 받아 종료 심볼 $<eos>$가 나올 때까지 연산을 진행합니다. <br>\n",
    "<br>\n",
    "이는 RNN은 사용되지 않지만 여전히 인코더-디코더의 구조는 유지되고 있음을 보여줍니다.\n",
    "<br>\n",
    "트랜스포머의 내부 구조를 조금씩 확대해가는 방식으로 트랜스포머를 이해해봅시다. <br>\n",
    "<br>\n",
    "\n",
    "우선 인코더와 디코더의 구조를 이해하기 전에 트랜스포머의 입력에 대해서 이해해보겠습니다.<br>\n",
    "\n",
    "트랜스포머의 인코더와 디코더는 단순히 각 단어의 임베딩 벡터들을 입력받는 것이 아니라 임베딩 벡터에서 조정된 값을 입력받는데 이에 대해서 알아보기 위해 입력 부분을 확대해보겠습니다.<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ced278",
   "metadata": {},
   "source": [
    "## 4. 포지셔널 인코딩(Positional Encoding)\n",
    "   \n",
    "   \n",
    "트랜스포머의 내부를 이해하기 전에 우선 **트랜스포머의 입력**에 대해서 알아보겠습니다. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "RNN이 자연어 처리에서 유용했던 이유는 단어의 위치에 따라 단어를 순차적으로 입력받아서 처리하는 RNN의 특성으로 인해 각 단어의 위치 정보(position information)를 가질 수 있다는 점에 있었습니다.<br>\n",
    "<br>\n",
    "하지만 트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있습니다. <br>\n",
    "<br>\n",
    "트랜스포머는 단어의 위치 정보를 얻기 위해서 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용하는데, 이를 포지셔널 인코딩(positional encoding)이라고 합니다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer5_final_final.PNG)\n",
    "<br>\n",
    "위의 그림은 입력으로 사용되는 임베딩 벡터들이 트랜스포머의 입력으로 사용되기 전에 포지셔널 인코딩의 값이 더해지는 것을 보여줍니다. <br>\n",
    "임베딩 벡터가 인코더의 입력으로 사용되기 전 포지셔널 인코딩값이 더해지는 과정을 시각화하면 아래와 같습니다.<br>\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer6_final.PNG)\n",
    "포지셔널 인코딩 값들은 어떤 값이기에 위치 정보를 반영해줄 수 있는 것일까요? 트랜스포머는 위치 정보를 가진 값을 만들기 위해서 아래의 두 개의 함수를 사용합니다.<br>\n",
    "<br>\n",
    "$PE_{(pos,\\ 2i)}=sin(pos/10000^{2i/d_{model}})$<br>\n",
    "$PE_{(pos,\\ 2i+1)}=cos(pos/10000^{2i/d_{model}})$<br>\n",
    "<br>\n",
    "사인 함수와 코사인 함수의 그래프를 상기해보면 요동치는 값의 형태를 생각해볼 수 있는데, 트랜스포머는 사인 함수와 코사인 함수의 값을 임베딩 벡터에 더해주므로서 단어의 순서 정보를 더하여 줍니다. <br>\n",
    "<br>\n",
    "그런데 위의 두 함수에는 $pos,i, d_{model}$등의 생소한 변수들이 있습니다. <br>\n",
    "위의 함수를 이해하기 위해서는 위에서 본 임베딩 벡터와 포지셔널 인코딩의 덧셈은 사실 임베딩 벡터가 모여 만들어진 문장 행렬과 포지셔널 인코딩 행렬의 덧셈 연산을 통해 이루어진다는 점을 이해해야 합니다.<br>\n",
    "<br>\n",
    "![](https://wikidocs.net/images/page/31379/transformer7.PNG)\n",
    "$pos$는 입력 문장에서의 임베딩 벡터의 위치를 나타내며, $i$는 임베딩 벡터 내의 차원의 인덱스를 의미합니다. <br>\n",
    "<br>\n",
    "위의 식에 따르면 임베딩 벡터 내의 각 차원의 인덱스가 짝수인 경우에는 사인 함수의 값을 사용하고 홀수인 경우에는 코사인 함수의 값을 사용합니다. <br>\n",
    "<br>\n",
    "위의 수식에서 $(pos,\\ 2i)$일 때는 사인 함수를 사용하고, $(pos,\\ 2i+1)$일 때는 코사인 함수를 사용하고 있음을 주목합시다.<br>\n",
    "<br>\n",
    "또한 위의 식에서 $d_{model}$은 트랜스포머의 모든 층에서 출력 차원을 의미하는 트랜스포머의 하이퍼파라미터입니다.<br>\n",
    "<br>\n",
    "앞으로 보게 될 트랜스포머의 각종 구조에서 $d_{model}$의 값이 계속해서 등장하는 이유입니다. <br>\n",
    "<br>\n",
    "임베딩 벡터 또한 $d_{model}$의 차원을 가지는데 위의 그림에서는 마치 4로 표현되었지만 실제 논문에서는 512의 값을 가집니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "위와 같은 포지셔널 인코딩 방법을 사용하면 순서 정보가 보존되는데, 예를 들어 각 임베딩 벡터에 포지셔널 인코딩의 값을 더하면 같은 단어라고 하더라도 문장 내의 위치에 따라서 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라집니다.<br>\n",
    "<br>\n",
    "이에 따라 트랜스포머의 입력은 순서정보가 고려된 임베딩 벡터가 됩니다. 이를 코드로 구현하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179727c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "        \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        \n",
    "        # 배열의 짝수 인덱스 (2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        \n",
    "        # 배열의 홀수 인덱스 (2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        \n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2aee8d",
   "metadata": {},
   "source": [
    "50 x 128의 크기를 가지는 포지셔널 인코딩 행렬을 시각화하여 어떤 형태를 가지는지 확인해봅시다.<br>\n",
    "이는 입력 문장의 단어가 50개이면서, 각 단어가 128차원의 임베딩 벡터를 가질 때 사용할 수 있는 행렬입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b556cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e060a",
   "metadata": {},
   "source": [
    "## 5. 어텐션(Attention)\n",
    "트랜스포머에서 사용되는 세 가지의 어텐션에 대해서 간단히 정리해봅시다. 지금은 큰 그림을 이해하는 것에만 집중합니다.<br>\n",
    "![](https://wikidocs.net/images/page/31379/attention.PNG)\n",
    "첫번째 그림인 셀프 어텐션은 인코더에서 이루어지지만, 두번째 그림인 셀프 어텐션과 세번째 그림인 인코더-디코더 어텐션은 디코더에서 이루어집니다.<br>\n",
    "<br>\n",
    "셀프 어텐션은 본질적으로 Query, Key, Value가 동일한 경우를 말합니다. <br>\n",
    "반면, 세번째 그림 인코더-디코더 어텐션에서는 Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터이므로 셀프 어텐션이라고 부르지 않습니다.<br>\n",
    "<br>\n",
    "* 주의할 점은 여기서 Query, Key 등이 같다는 것은 벡터의 값이 같다는 것이 아니라 벡터의 출처가 같다는 의미입니다.<br>\n",
    "\n",
    "<br>정리하면 다음과 같습니다.\n",
    "```\n",
    "인코더의 셀프 어텐션 : Query = Key = Value\n",
    "디코더의 마스크드 셀프 어텐션 : Query = Key = Value\n",
    "디코더의 인코더-디코더 어텐션 : Query : 디코더 벡터 / Key = Value : 인코더 벡터\n",
    "```\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer_attention_overview.PNG)\n",
    "<br>\n",
    "위 그림은 트랜스포머의 아키텍처에서 세가지 어텐션이 각각 어디에서 이루어지는지를 보여줍니다.<br>\n",
    "세 개의 어텐션에 추가적으로 '멀티 헤드'라는 이름이 붙어있습니다. 이는 트랜스포머가 어텐션을 병렬적으로 수행하는 방법을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27902a27",
   "metadata": {},
   "source": [
    "## 6. 인코더(Encoder)\n",
    "<br>\n",
    "인코더의 구조에 대해서 알아보겠습니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer9_final_ver.PNG)\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 $\\text{num_layers}$ 개수의 인코더 층을 쌓습니다.<br>\n",
    "논문에서는 총 6개의 인코더 층을 사용하였습니다. 인코더를 하나의 층이라는 개념으로 생각한다면, 하나의 인코더 층은 크게 총 2개의 서브층(sublayer)으로 나뉘어집니다.<br>\n",
    "<br>\n",
    "셀프 어텐션과 피드 포워드 신경망입니다. 위의 그림에서는 멀티 헤드 셀프 어텐션과 포지션 와이즈 피드 포워드 신경망이라고 적혀있지만, <br>\n",
    "멀티 헤드 셀프 어텐션은 셀프 어텐션을 병렬적으로 사용하였다는 의미고, 포지션 와이즈 피드 포워드 신경망은 우리가 알고있는 일반적인 피드 포워드 신경망입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf6a8e",
   "metadata": {},
   "source": [
    "## 7. 인코더의 셀프 어텐션\n",
    "<br>\n",
    "트랜스포머에서는 셀프 어텐션이라는 어텐션 기법이 등장하는데 앞서 배웠던 어텐션 함수에 대해서 복습하고, 셀프 어텐션이 앞서 배웠던 어텐션과 무엇이 다른지 알아보겠습니다.<br>\n",
    "<br>\n",
    "### 1) 셀프 어텐션의 의미와 이점\n",
    "<br>\n",
    "어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다. 그리고 구해낸 이 유사도를 가중치로 하여 키와 맵핑되어있는 각각의 '값(Value)'에 반영해줍니다.<br>\n",
    "<br>\n",
    "\n",
    "그리고 유사도가 반영된 '값(Value)'을 모두 가중합하여 리턴합니다.\n",
    "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)\n",
    "<br>\n",
    "여기까지는 앞서 배운 어텐션의 개념입니다. 그런데 어텐션 중에서는 셀프 어텐션(self-attention)이라는 것이 있습니다. <br>\n",
    "<br>\n",
    "어텐션을 자기 자신에게 수행한다는 의미입니다. 앞서 배운 seq2seq에서 어텐션을 사용할 경우의 Q, K, V의 정의를 다시 생각해봅시다.\n",
    "<br>\n",
    "```\n",
    "Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```\n",
    "<br>\n",
    "사실 t 시점이라는 것은 계속 변화하면서 반복적으로 쿼리를 수행하므로 결국 전체 시점에 대해서 일반화를 할 수도 있습니다.<br>\n",
    "<br>\n",
    "\n",
    "```\n",
    "Q = Querys : 모든 시점의 디코더 셀에서의 은닉 상태들\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```\n",
    "\n",
    "이처럼 기존에는 디코더 셀의 은닉 상태가 Q이고 인코더 셀의 은닉 상태가 K라는 점에서 Q와 K가 서로 다른 값을 가지고 있었습니다.<br>\n",
    "<br>\n",
    "그런데 셀프 어텐션에서는 Q, K, V가 전부 동일합니다. 트랜스포머의 셀프 어텐션에서의 Q, K, V는 아래와 같습니다.<br>\n",
    "<br>\n",
    "\n",
    "```\n",
    "Q : 입력 문장의 모든 단어 벡터들\n",
    "K : 입력 문장의 모든 단어 벡터들\n",
    "V : 입력 문장의 모든 단어 벡터들\n",
    "```\n",
    "\n",
    "셀프 어텐션에 대한 구체적인 사항을 배우기 전에 셀프 어텐션을 통해 얻을 수 있는 대표적인 효과에 대해서 이해해봅시다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer10.png)\n",
    "\n",
    "<br>\n",
    "위의 그림은 트랜스포머에 대한 구글 AI 블로그 포스트에서 가져왔습니다. <br>\n",
    "<br>\n",
    "위의 예시 문장을 번역하면 '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.' 라는 의미가 됩니다. <br>\n",
    "<br>\n",
    "그런데 여기서 그것(it)에 해당하는 것은 과연 길(street)일까요? 동물(animal)일까요? 우리는 피곤한 주체가 동물이라는 것을 아주 쉽게 알 수 있지만 기계는 그렇지 않습니다. <br>\n",
    "<br>\n",
    "하지만 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하므로서 그것(it)이 동물(animal)과 연관되었을 확률이 높다는 것을 찾아냅니다.<br>\n",
    "<br>\n",
    "트랜스포머에서의 셀프 어텐션의 동작 메커니즘을 알아봅시다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39208af",
   "metadata": {},
   "source": [
    "### 2) Q, K, V 벡터 얻기\n",
    "<br>\n",
    "앞서 셀프 어텐션은 입력 문장의 단어 벡터들을 가지고 수행한다고 하였는데, 사실 셀프 어텐션은 인코더의 초기 입력인 $d_{model}$의 차원을 가지는 단어 벡터들을 사용하여 셀프 어텐션을 수행하는 것이 아니라<br>\n",
    "우선 각 단어 벡터들로부터 Q벡터, K벡터, V벡터를 얻는 작업을 거칩니다.<br>\n",
    "<br>\n",
    "이때 이 Q벡터, K벡터, V벡터들은 초기 입력인 $d_{model}$의 차원을 가지는 단어 벡터들보다 더 작은 차원을 가지는데, <br>\n",
    "논문에서는 $d_{model} = 512$의 차원을 가졌던 각 단어 벡터들을 64의 차원을 가지는 Q벡터, K벡터, V벡터로 변환하였습니다.<br>\n",
    "<br>\n",
    "64라는 값은 트랜스포머의 또 다른 하이퍼파라미터인 $\\text{num_heads}$로 인해 결정되는데, 트랜스포머는 $d_{model}$을 $\\text{num_heads}$로 나눈 값을 각 Q벡터, K벡터, V벡터의 차원으로 결정합니다.<br>\n",
    "<br>\n",
    "논문에서는 $\\text{num_heads}$를 8로 하였습니다. 그림을 통해 이해해봅시다.<br>\n",
    "<br>\n",
    "예를 들어 여기서 사용하고 있는 예문 중 student라는 단어 벡터를 Q, K, V의 벡터로 변환하는 과정을 보겠습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer11.PNG)\n",
    "<br>\n",
    "기존의 벡터로부터 더 작은 벡터는 가중치 행렬을 곱하므로서 완성됩니다. 각 가중치 행렬은 $d_{model} × (d_{model}\\text{/num_heads})$의 크기를 가집니다.<br>\n",
    "<br>\n",
    "이 가중치 행렬은 훈련 과정에서 학습됩니다. 즉, 논문과 같이 $d_{model}=512$이고 $\\text{num_heads}=8$라면, 각 벡터에 3개의 서로 다른 가중치 행렬을 곱하고 64의 크기를 가지는 Q, K, V 벡터를 얻어냅니다.<br>\n",
    "<br>\n",
    "위의 그림은 단어 벡터 중 student벡터로부터 Q, K, V벡터를 얻어내는 모습을 보여줍니다. 모든 단어 벡터에 위와 같은 과정을 거치면 I, am, a, student는 각각의 Q, K, V벡터를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a73985",
   "metadata": {},
   "source": [
    "### 3) 스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)\n",
    "<br>\n",
    "Q, K, V벡터를 얻었다면 지금부터는 기존에 배운 어텐션 메커니즘과 동일합니다.<br>\n",
    "각 Q벡터는 모든 K벡터에 대해서 어텐션 스코어를 구하고 어텐션 분포를 구한 뒤에 이를 사용하여 모든 V벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구하게 됩니다.<br>\n",
    "그리고 이를 모든 Q벡터에 대해서 반복합니다.<br>\n",
    "<br>\n",
    "그런데 앞서 어텐션 챕터에서 어텐션 함수의 종류는 다양하다고 언급한 바 있습니다. <br>\n",
    "<br>\n",
    "트랜스포머에서는 내적만을 사용하는 어텐션 함수 $score(q, k)=q⋅k$가 아니라 여기에 특정값으로 나눠준 어텐션 함수인 $score(q, k)=q⋅k/\\sqrt{n}$를 사용합니다.<br>\n",
    "<br>\n",
    "이러한 함수를 사용하는 어텐션을 닷-프로덕트 어텐션(dot-product attention)에서 값을 스케일링하는 것을 추가하였다고 하여\n",
    "\n",
    "**스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)**이라고 합니다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer13.PNG)\n",
    "<br>\n",
    "우선 단어 I에 대한 Q벡터를 기준으로 설명해보겠습니다. 지금부터 설명하는 과정은 am에 대한 Q벡터, a에 대한 Q벡터, student에 대한 Q벡터에 대해서도 모두 동일한 과정을 거칩니다. <br>\n",
    "<br>\n",
    "위의 그림은 단어 I에 대한 Q벡터가 모든 K벡터에 대해서 어텐션 스코어를 구하는 것을 보여줍니다. 위의 128과 32는 저자가 임의로 가정한 수치로 신경쓰지 않아도 좋습니다.<br>\n",
    "<br>\n",
    "위의 그림에서 어텐션 스코어는 각각 단어 I가 단어 I, am, a, student와 얼마나 연관되어 있는지를 보여주는 수치입니다. <br>\n",
    "<br>\n",
    "트랜스포머에서는 두 벡터의 내적값을 스케일링하는 값으로 K벡터의 차원을 나타내는 $d_{k}$에 루트를 씌운 $\\sqrt{d_{k}}$ 사용하는 것을 택했습니다.<br>\n",
    "<br>\n",
    "앞서 언급하였듯이 논문에서 $d_{k}$는 $d_{model}\\text{/num_heads}$라는 식에 따라서 64의 값을 가지므로 $\\sqrt{d_{k}}$ 는 8의 값을 가집니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer14_final.PNG)\n",
    "\n",
    "이제 어텐션 스코어에 소프트맥스 함수를 사용하여 어텐션 분포(Attention Distribution)을 구하고, 각 V벡터와 가중합하여 어텐션값(Attention Value)을 구합니다. <br>\n",
    "<br>\n",
    "이를 단어 I에 대한 어텐션 값 또는 단어 I에 대한 컨텍스트 벡터(context vector)라고도 할 수 있습니다. <br>\n",
    "<br>\n",
    "am에 대한 Q벡터, a에 대한 Q벡터, student에 대한 Q벡터에 대해서도 모두 동일한 과정을 반복하여 각각에 대한 어텐션 값을 구합니다.<br>\n",
    "<br>\n",
    "그런데 한가지 의문이 생깁니다. 굳이 각 Q벡터마다 일일히 따로 연산할 필요가 있을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23fca9",
   "metadata": {},
   "source": [
    "### 4) 행렬 연산으로 일괄 처리하기\n",
    "사실 각 단어에 대한 Q, K, V 벡터를 구하고 스케일드 닷-프로덕트 어텐션을 수행하였던 위의 과정들은 벡터 연산이 아니라 행렬연산을 사용하면 일괄 계산이 가능합니다. <br>\n",
    "<br>\n",
    "지금까지 벡터 연산으로 설명하였던 이유는 이해를 돕기 위한 과정이고 실제로는 행렬 연산으로 구현됩니다.<br>\n",
    "<br>\n",
    "위의 과정을 벡터가 아닌 행렬 연산으로 이해해봅시다. 우선, 각 단어 벡터마다 일일히 가중치 행렬을 곱하는 것이 아니라 문장 행렬에 가중치 행렬을 곱하여 Q행렬, K행렬, V행렬을 구합니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer12.PNG)\n",
    "\n",
    "행렬 연산을 통해 어텐션 스코어는 어떻게 구할 수 있을까요?<br>\n",
    "<br>\n",
    "여기서 Q행렬을 K행렬을 전치한 행렬과 곱해준다고 해봅시다. 이렇게 되면 각각의 단어의 Q벡터와 K벡터의 내적이 각 행렬의 원소가 되는 행렬이 결과로 나옵니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer15.PNG)\n",
    "\n",
    "다시 말해 위의 그림의 결과 행렬의 값에 전체적으로 $\\sqrt{d_{k}}$를 나누어주면 이는 각 행과 열이 어텐션 스코어 값을 가지는 행렬이 됩니다.<br>\n",
    "<br>\n",
    "예를 들어 I행과 student열의 값은 I의 Q벡터와 student의 K벡터의 어텐션 스코어 값입니다. 위 행렬을 어텐션 스코어 행렬이라 합시다.<br>\n",
    "<br>\n",
    "어텐션 스코어 행렬을 구하였다면 남은 것은 어텐션 분포를 구하고 이를 사용하여 모든 단어에 대한 어텐션 값을 구하는 일입니다.<br>\n",
    "<br>\n",
    "이는 간단하게 어텐션 스코어 행렬에 소프트맥스 함수를 사용하고 V행렬을 곱하는 것으로 해결됩니다.<br>\n",
    "<br>\n",
    "이렇게 되면 각 단어의 어텐션 값을 모두 가지는 어텐션 값 행렬이 결과로 나옵니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer16.PNG)\n",
    "\n",
    "위의 그림은 행렬 연산을 통해 모든 값이 일괄 계산되는 과정을 식으로 보여줍니다. <br>\n",
    "<br>\n",
    "해당 식은 실제 트랜스포머 논문에 기재된 아래 수식과 정확하게 일치하는 식입니다.<br>\n",
    "<br>\n",
    "$Attention(Q, K, V) = softmax({QK^T\\over{\\sqrt{d_k}}})V$\n",
    "<br>\n",
    "위의 행렬 연산에 사용된 행렬의 크기를 모두 정리해봅시다. <br>\n",
    "<br>\n",
    "우선 입력 문장의 길이를 seq_len이라고 해봅시다. 그렇다면 문장행렬의 크기는 $(\\text{seq_len},\\ d_{model})$입니다.<br>\n",
    "<br>\n",
    "여기에 3개의 가중치 행렬을 곱해서 Q, K, V행렬을 만들어야 합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "우선 행렬의 크기를 정의하기 위해 행렬의 각 행에 해당되는 Q벡터와 K벡터의 차원을 $d_{k}$라고 하고, V벡터의 차원을 $d_{v}$라고 해봅시다.<br>\n",
    "<br>\n",
    "그렇다면 Q행렬과 K행렬의 크기는 $(\\text{seq_len},\\ d_{k})$이며 V행렬의 크기는 $(\\text{seq_len},\\ d_{v})$가 되어야 합니다. <br>\n",
    "<br>\n",
    "그렇다면 문장 행렬과 Q, K, V 행렬의 크기로부터 가중치 행렬의 크기 추정이 가능합니다. <br>\n",
    "<br>\n",
    "$W^{Q}$와 $W^{K}$는 $(d_{model},\\ d_{k})$의 크기를 가지며, $W^{V}$는 $(d_{model},\\ d_{v})$의 크기를 가집니다. 단, 논문에서는 $d_{k}$와 $d_{v}$의 차원은 $d_{model}\\text{/num_heads}$와 같습니다.<br>\n",
    "<br>\n",
    "즉, $d_{model}\\text{/num_heads}= d_{k}=d_{v}$입니다.<br>\n",
    "<br>\n",
    "결과적으로 $softmax({QK^T\\over{\\sqrt{d_k}}})V$식을 적용하여 나오는 어텐션 값 행렬 $a$의 크기는 $(\\text{seq_len},\\ d_{v})$이 됩니다.<br>\n",
    "<br>\n",
    "코드로 작성하면 아래와 같습니다.\n",
    "<br>\n",
    "<br>\n",
    "### 5) 스케일드 닷-프로덕트 어텐션 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1676aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장길이)\n",
    "    \n",
    "    # Q와 K의 곱. djxpstus tmzhdj godfuf.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "        \n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    #  attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=1)\n",
    "    \n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e230f",
   "metadata": {},
   "source": [
    "Q행렬과 K행렬을 전치한 행렬을 곱하고, 소프트맥스 함수를 사용하여 어텐션 분포 행렬을 얻은 뒤에 V행렬과 곱합니다. 코드에서 mask가 사용되는 if문은 아직 배우지 않은 내용으로 지금은 무시합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "scaled_dot_product_attention 함수가 정상 작동하는지 테스트를 해보겠습니다.<br>\n",
    "<br>\n",
    "우선 temp_q, temp_k, temp_v라는 임의의 Query, Key, Value행렬을 만들고 이를 scaled_dot_product_attention 함수에 입력으로 넣어 함수가 리턴하는 값을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c4beb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[    1,0],\n",
    "                      [   10,0],\n",
    "                      [  100,5],\n",
    "                      [ 1000,6]], dtype=tf.float32) # (3, 2)\n",
    "\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32) # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed1b04",
   "metadata": {},
   "source": [
    "여기서 주목할 점은 Query에 해당하는 temp_q의 값 [0, 10, 0]은 Key에 해당하는 temp_k의 두번째 값 [0, 10, 0]과 일치한다는 점입니다. <br>\n",
    "그렇다면 어텐션 분포와 어텐션 값은 과연 어떤 값이 나올까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efa1aea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce7170",
   "metadata": {},
   "source": [
    "Query는 4개의 Key값 중 두번째 값과 일치하므로 어텐션 분포는 [0, 1, 0, 0]의 값을 가지며 결과적으로 Value의 두번째 값인 [10, 0]이 출력되는 것을 확인할 수 있습니다. 이번에는 Query의 다른 값으로 바꿔보고 함수를 실행해봅시다.<br>\n",
    "<br>\n",
    "이번에 사용할 Query값 [0, 0, 10]은 Key의 세번째 값과 네번째 값 두 개의 값 모두와 일치하는 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e13d0877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out , temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn)  # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out)   # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb726eb",
   "metadata": {},
   "source": [
    "Query의 값은 Key의 세번째 값과 네번째 값 두 개의 값과 모두 유사하다는 의미에서 어텐션 분포는 [0, 0, 0.5, 0.5]의 값을 가집니다.<br>\n",
    "<br>\n",
    "결과적으로 나오는 값 [550, 5.5]는 Value의 세번째 값 [100, 5]에 0.5를 곱한 값과 네번째 값 [1000, 6]에 0.5를 곱한 값의 원소별 합입니다.<br>\n",
    "<br>\n",
    "이번에는 하나가 아닌 3개의 Query의 값을 함수의 입력으로 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99a260ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn)  # 어텐션의 분포(어텐션 가중치의 나열)\n",
    "print(temp_out)   # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fca2c",
   "metadata": {},
   "source": [
    "### 6) 멀티 헤드 어텐션(Multi-head Attention)\n",
    "<br>\n",
    "앞서 배운 어텐션에서는 $d_{model}$의 차원을 가진 단어 벡터를 $\\text{num_heads}$로 나눈 차원을 가지는 Q, K, V벡터로 바꾸고 어텐션을 수행하였습니다.<br>\n",
    "<br>\n",
    "논문 기준으로는 512의 차원의 각 단어 벡터를 8로 나누어 64차원의 Q, K, V벡터로 바꾸어서 어텐션을 수행한 셈인데, <br>\n",
    "이제 $\\text{num_heads}$의 의미와 왜 $d_{model}$의 차원을 가진 단어 텍터를 가지고 어텐션을 하지않고 차원을 축소시킨 벡터로 어텐션을 수행하였는지 이해해보겠습니다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer17.PNG)\n",
    "\n",
    "<br>\n",
    "트랜스포머 연구진은 한번의 어텐션을 하는 것보다 여러번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단하였습니다.<br>\n",
    "<br>\n",
    "그래서 $d_{model}$의 차원을 $\\text{num_heads}$개로 나누어 $d_{model}\\text{/num_heads}$의 차원을 가지는 Q, K, V에 대해서 $\\text{num_heads}$개의 병렬 어텐션을 수행합니다.<br>\n",
    "<br>\n",
    "논문에서는 하이퍼파라미터인 $\\text{num_heads}$의 값을 8로 지정하였고, 8개의 병렬 어텐션이 이루어지게 됩니다.<br>\n",
    "<br>\n",
    "다시 말해 위에서 설명한 어텐션이 8개로 병렬로 이루어지게 되는데, 이때 각각의 어텐션 값 행렬을 어텐션 헤드라고 부릅니다.<br>\n",
    "<br>\n",
    "이때 가중치 행렬 $W^{Q}, W^{K}, W^{V}$의 값은 8개의 어텐션 헤드마다 전부 다릅니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "멀티 헤드 어텐션으로 얻을 수 있는 효과? 어텐션을 병렬로 수행하여 각각 다른 시각으로 정보를 수집하겠다는 것<br>\n",
    "ex) 케르베로스, 히드라와 같이 머리가 여러개면 시야가 넓듯<br>\n",
    "<br>\n",
    "<br>\n",
    "예를 들어 '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.'에서 단어 그것(it)이 쿼리였다고 가정하자.<br>\n",
    "<br>\n",
    "즉, it에 대한 Q벡터로부터 다른 단어와의 연관도를 구하였을 때 첫번째 어텐션 헤드는 '그것(it)'과 '동물(animal)'의 연관도를 높게 본다면, <br>\n",
    "두번째 어텐션헤드는 '그것(it)'과 '피곤하였기 때문이다(tired)'의 연관도를 높게 볼 수 있습니다.<br>\n",
    "이는 각 어텐션 헤드는 전부 다른 시각에서 보고있기 때문입니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer18_final.PNG)\n",
    "\n",
    "<br>\n",
    "병렬 어텐션을 모두 수행하였다면 모든 어텐션 헤드를 연결(concatenate)합니다.<br>\n",
    "모두 연결된 어텐션 헤드 행렬의 크기는 $(\\text{seq_len},\\ d_{model})$가 됩니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "지금까지의 그림에서는 4차원을 $d_{model}=512$로 표현하고, 2차원을 $d_{v}=64$로 표현해왔기 때문에 위의 그림의 행렬의 크기에 혼동이 있을 수 있으나 <br>\n",
    "8개의 어텐션 헤드의 연결(concatenate)과정의 이해를 위해 이번 행렬만 예외로 위와 같이 $d_{model}$의 크기를 $d_{v}$의 8배인 16차원으로 표현하였습니다.<br>\n",
    "아래의 그림에서는 다시 $d_{model}$를 4차원으로 표현합니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer19.PNG)\n",
    "\n",
    "어텐션 헤드를 모두 연결한 행렬은 또 다른 가중치 행렬 $W^{O}$을 곱하게 되는데, 이렇게 나온 결과 행렬이 멀티-헤드 어텐션의 최종결과물입니다.<br>\n",
    "<br>\n",
    "\n",
    "위의 그림은 어텐션 헤드를 모두 연결한 행렬이 가중치 행렬 $W^{O}$과 곱해지는 과정을 보여줍니다. <br>\n",
    "<br>\n",
    "이때 결과물인 멀티-헤드 어텐션 행렬은 인코더의 입력이었던 문장 행렬의 $(\\text{seq_len},\\ d_{model})$크기와 동일합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "다시 말해 인코더의 첫번째 서브층인 멀티-헤드 어텐션 단계를 끝마쳤을 때, 인코더의 입력으로 들어왔던 행렬의 크기가 아직 유지되고 있음을 기억해둡시다.<br>\n",
    "<br>\n",
    "첫번째 서브층인 멀티-헤드 어텐션과 두번째 서브층인 포지션 와이즈 피드 포워드 신경망을 지나면서 인코더의 입력으로 들어올 때의 행렬의 크기는 계속 유지되어야 합니다.<br>\n",
    "<br>\n",
    "트랜스포머는 동일한 구조의 인코더를 쌓은 구조입니다. 논문 기준으로는 인코더가 총 6개입니다. <br>\n",
    "<br>\n",
    "인코더에서의 입력의 크기가 출력에서도 동일 크기로 계속 유지되어야만 다음 인코더에서도 다시 입력이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37ecff",
   "metadata": {},
   "source": [
    "### 7) 멀티 헤드 어텐션(Multi-head Attention) 구현하기\n",
    "<br>\n",
    "멀티 헤드 어텐션에서는 크게 두 종류의 가중치 행렬이 나왔습니다. Q, K, V행렬을 만들기 위한 가중치 행렬인 $W^Q, W^K, W^V$행렬과 바로 어텐션 헤드들을 연결(concatenation) 후에 곱해주는 WO행렬입니다.<br>\n",
    "<br>\n",
    "가중치 행렬을 곱하는 것을 구현 상에서는 입력을 전결합층.<br>\n",
    "<br>\n",
    "즉, 밀집층(Dense layer)을 지나게 하여 구현합니다. 케라스 코드상으로 지금까지 사용해왔던 Dense()에 해당됩니다.\n",
    "\n",
    "```\n",
    "Dense(units)\n",
    "```\n",
    "\n",
    "멀티 헤드 어텐션의 구현은 크게 다섯가지 파트로 구성됩니다.\n",
    "<br><br><br>\n",
    "1. $W^Q, W^K, W^V$에 해당되는 $d_{model}$크기의 밀집층(Dense layer)을 지나게 한다.<br>\n",
    "2. 지정된 헤드 수($\\text{num_heads}$)만큼 나눈다.(split)<br>\n",
    "3. 스케일드 닷 프로덕트 어텐션<br>\n",
    "4. 나눠졌던 헤드들을 연결(concatenation)한다.<br>\n",
    "5. $W^O$에 해당하는 밀집층을 지나게 한다.<br>\n",
    "<br>\n",
    "이론으로 설명할 때보다 심플하게 구성되었는데 결국 근본적으로 동일한 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8318e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        # d_model을 num_heads로 나눈 값\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "    # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape = (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        # 참고) 인코더(k, v) - 디코더)(q) 어텐션에서는 query길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled-dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                     (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f7ffe",
   "metadata": {},
   "source": [
    "### 8) 패딩 마스트(Padding Mask)\n",
    "아직 설명하지 않은 내용이 있습니다. 앞서 구현한 스케일드 닷 프로덕트 어텐션 함수 내부를 보면 amsk라는 값을 인자로 받아서,<br>\n",
    "<br>\n",
    "이 mask값에다가 -1e9라는 아주 작은 음수값을 곱한 후 어텐션 스코어 행렬에 더해주고 있습니다. 이 연산의 정체는 무엇일까요?\n",
    "\n",
    "```python\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "... 중략 ...\n",
    "    logits += (mask * -1e9) # 어텐션 스코어 행렬인 logits에 mask*-1e9 값을 더해주고 있다.\n",
    "... 중략 ...\n",
    "```\n",
    "\n",
    "이는 입력 문장에 $\\text{<PAD>}$토큰이 있을 경우 어텐션에서 사실상 제외하기 위한 연산입니다.<br>\n",
    "<br>\n",
    "예를 들어 $\\text{<PAD>}$가 포함된 입력 문장의 셀프 어텐션의 예제를 봅시다. <br>\n",
    "<br>\n",
    "이에 대해서 어텐션을 수행하고 어텐션 스코어 행렬을 얻는 과정은 다음과 같습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/pad_masking11.PNG)\n",
    "\n",
    "그런데 사실 단어 $\\text{<PAD>}$의 경우에는 실질적인 의미를 가진 단어가 아닙니다. 그래서 트랜스포머에서는 Key의 경우에 $\\text{<PAD>}$토큰이 존재한다면 이에 대해서는 유사도를 구하지 않도록 마스킹(Masking)을 해주기로 했습니다.<br>\n",
    "<br>\n",
    "여기서 마스킹이란 어텐션에서 제외하기 위해 값을 가린다는 의미입니다. <br>\n",
    "<br>\n",
    "어텐션 스코어 행렬에서 행에 해당하는 문장은 Query이고, 열에 해당하는 문장은 Key입니다. 그리고 Key에 $\\text{<PAD>}$가 있는 경우에는 해당 열 전체를 마스킹 해줍니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/pad_masking2.PNG)\n",
    "\n",
    "마스킹하는 방법은 어텐션 스코어 행렬의 마스킹 위치에 매우 작은 음수값을 넣어주는 것입니다.<br>\n",
    "<br>\n",
    "여기서 매우 작은 음수값이 라는 것은 -1,000,000,000과 같은 마이너스 무한대에 가까운 수라는 의미입니다. 현재 어텐션 스코어 함수는 소프트맥스 함수를 지나지 않은 상태입니다.<br>\n",
    "<br>\n",
    "앞서 배운 연산 순서라면 어텐션 스코어 함수는 소프트맥스 함수를 지나고, 그 후 Value행렬과 곱해지게 됩니다.<br>\n",
    "<br>\n",
    "그런데 현재 마스킹 위치에 매우 작은 음수 값이 들어가 있으므로 어텐션 스코어 행렬이 스프트맥스 함수를 지난 후에는 해당 위치값은 0이 되어 단어 간 유사도를 구하는 일에 $\\text{<PAD>}$토큰이 반영되지 않게 됩니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/softmax.PNG)\n",
    "\n",
    "<br>\n",
    "위 그림은 소프트맥스 함수를 지난 후를 가정하고 있습니다. 소프트맥스 함수를 지나면 각 행의 어텐션 가중치의 총 합은 1이 되는데, 단어 $\\text{<PAD>}$의 경우에는 0이 되어 어떤 유의미한 값을 가지고 있지 않습니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "패딩 마스크를 구현하는 방법은 입력된 정수 시퀀스에서 패딩 토큰의 인덱스인지, 아닌지를 판별하는 함수를 구현하는 것입니다.<br>\n",
    "아래의 함수는 정수 시퀀스에서 0인 경우에는 1로 변환하고, 그렇지않은 경우에는 0으로 변환하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b641f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6732b8",
   "metadata": {},
   "source": [
    "임의의 정수 시퀀스 입력을 넣어서 어떻게 변환되는지 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb362965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d83a3",
   "metadata": {},
   "source": [
    "위 벡터를 통해서 1의 값을 가진 위치의 열을 어텐션 스코어 행렬에서 마스킹하는 용도로 사용할 수 있습니다. <br>\n",
    "위 벡터를 스케일드 닷 프로덕트 어텐션의 인자로 전달하면, 스케일드 닷 프로덕트 어텐션에서는 위 벡터에다가 매우 작은 음수값인 -1e9를 곱하고, 이를 행렬에 더해주어 해당 열을 전부 마스킹합니다.<br>\n",
    "<br>\n",
    "첫번째 서브층인 멀티 헤드 어텐션을 구현해보았습니다. <br>\n",
    "앞서 인코더는 두 개의 서브 서브층(sublayer)으로 나뉘어진다고 언급한 적이 있는데, 두번째 서브층인 포지션-와이즈 피드 포워드 신경망에 대해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ce625",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 8. 포지션-와이즈 피드 포워드 신경망(Position-wise FFNN)<br>\n",
    "<br>\n",
    "\n",
    "지금은 인코더를 설명하고 있지만, 포지션 와이즈 FFNN은 인코더와 디코더에서 공통적으로 가지고 있는 서브층입니다.<br>\n",
    "포지션 와이즈 FFNN는 쉽게 말하면 완전 연결 FFNN(Fully-connected FFNN)이라고 해석할 수 있습니다.<br>\n",
    "앞서 인공신경망은 결국 벡터와 행렬 연산으로 표현될 수 있음을 배웠습니다. 아래는 포지션 와이즈 FFNN의 수식을 보여줍니다.<br>\n",
    "<br>\n",
    "$FFNN(x) = MAX(0, x{W_{1}} + b_{1}){W_2} + b_2$<br>\n",
    "<br>\n",
    "식을 그림으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/positionwiseffnn.PNG)\n",
    "\n",
    "여기서 $x$는 앞서 멀티 헤드 어텐션의 결과로 나온 $(\\text{seq_len},\\ d_{model})$의 크기를 가지는 행렬을 말합니다.<br>\n",
    "가중치 행렬 $W_1$은 $(d_{model},\\ d_{ff})$의 크기를 가지고 가중치 행렬 $W_2$은 $(d_{ff},\\ d_{model})$의 크기를 가집니다.<br>\n",
    "논문에서 은닉층의 크기인 $d_{ff}$는 앞서 하이퍼파라미터를 정의할 때 언급했듯이 2,048의 크기를 가집니다.<br>\n",
    "<br>\n",
    "여기서 매개변수 $W_1, b_{1}, W_2, b_2$는 하나의 인코더 층 내에서는 다른 문장, 다른 단어들마다 정확하게 동일하게 사용됩니다.<br>\n",
    "하지만 인코더 층마다는 다른 값을 가집니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer20.PNG)\n",
    "\n",
    "위의 그림에서 좌측은 인코더의 입력을 벡터 단위로 봤을 때, 각 벡터들이 멀티 헤드 어텐션 층이라는 인코더 내 첫번째 서브 층을 지나 FFNN을 통과하는 것을 보여줍니다.<br>\n",
    "<br>\n",
    "이는 두번째 서브층인 Position-wise FFNN을 의미합니다. 물론, 실제로는 그림 우측과 같이 행렬로 연산되는데, 두번째 서브층을 지난 인코더의 최종 출력은 여전히 인코더의 입력의 크기였던 $(\\text{seq_len},\\ d_{model})$의 크기가 보존되고 있습니다.<br>\n",
    "<br>\n",
    "하나의 인코더 층을 지난 이 행렬은 다음 인코더 층으로 전달되고, 다음 층에서도 동일한 인코더 연산이 반복됩니다.<br>\n",
    "<br>\n",
    "이를 구현하면 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "# 다음의 코드는 인코더와 디코더 내부에서 사용할 예정입니다.\n",
    "outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8496eb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 9. 잔차 연결(Residual connection)과 층 정규화(Layer Normalization)\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer21.PNG)\n",
    "\n",
    "인코더의 두 개의 서브층에 대해서 이해하였다면 인코더에 대한 설명은 거의 끝났습니다.<br>\n",
    "트랜스포머에서는 이러한 두 개의 서브층을 가진 인코더에 추가적으로 사용하는 기법이 있는데, 바로 Add & Norm입니다. <br>\n",
    "더 정확히는 잔차 연결(residual connection)과 층 정규화(layer normalization)를 의미합니다.<br>\n",
    "<br>\n",
    "<br>\n",
    "### 1) 잔차 연결(Residual connection)\n",
    "<br>\n",
    "잔차 연결(residual connection)의 의미를 이해하기 위해서 어떤 함수 $H(x)$에 대한 이야기를 해보겠습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/transformer22.PNG)\n",
    "\n",
    "위 그림은 입력 $x$와 $x$에 대한 어떤 함수 $F(x)$의 값을 더한 함수 $H(x)$의 구조를 보여줍니다. <br>\n",
    "<br>\n",
    "어떤 함수 $F(x)$가 트랜스포머에서는 서브층에 해당됩니다. 다시 말해 잔차 연결은 서브층의 입력과 출력을 더하는 것을 말합니다. <br>\n",
    "<br>\n",
    "앞서 언급했듯이 트랜스포머에서 서브층의 입력과 출력은 동일한 차원을 갖고 있으므로, 서브층의 입력과 서브층의 출력은 덧셈 연산을 할 수 있습니다. <br>\n",
    "<br>\n",
    "이것이 바로 위의 인코더 그림에서 각 화살표가 서브층의 입력에서 출력으로 향하도록 그려졌던 이유입니다. <br>\n",
    "잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습을 돕는 기법입니다.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "이를 식으로 표현하면 $x+Sublayer(x)$입니다.<br>\n",
    "<br>\n",
    "가령, 서브층이 멀티 헤드 어텐션이었다면 잔차 연결 연산은 다음과 같습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/residual_connection.PNG)\n",
    "\n",
    "위 그림은 멀티 헤드 어텐션의 입력과 멀티 헤드 어텐션의 결과가 더해지는 과정을 보여줍니다.<br>\n",
    "<br>\n",
    "관련 논문 : https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf363a4",
   "metadata": {},
   "source": [
    "### 2) 층 정규화(Layer Normalization)\n",
    "<br>\n",
    "잔차 연결을 거친 결과는 이어서 층 정규화 과정을 거치게됩니다. <br>\n",
    "잔차 연결의 입력을 $x$, 잔차 연결과 층 정규화 두 가지 연산을 모두 수행한 후의 결과 행렬을 $LN$이라고 하였을 때, 잔차 연결 후 층 정규화 연산을 수식으로 표현하자면 다음과 같습니다.<br>\n",
    "<br>\n",
    "$LN = LayerNorm(x+Sublayer(x))$\n",
    "<br>\n",
    "\n",
    "층 정규화를 하는 과정에 대해서 이해해보자. 층 정규화는 **텐서의 마지막 차원**에 대해서 평균과 분산을 구하고 이를 가지고 어떤 수식을 통해 값을 정규화하여 학습을 돕습니다. <br>\n",
    "\n",
    "\n",
    "여기서 텐서의 마지막 차원이란 것은 트랜스포머에서는 $d_{model}$차원을 의미합니다. 아래 그림은 $d_{model}$차원의 방향을 화살표로 표현하였습니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/layer_norm_new_1_final.PNG)\n",
    "\n",
    "<br>\n",
    "\n",
    "층 정규화를 위해서 우선, 화살표 방향으로 각각 평균 $μ$과 분산 $σ^{2}$을 구합니다. 각 화살표 방향의 벡터를 $x_{i}$라고 명명해봅시다.<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/layer_norm_new_2_final.PNG)\n",
    "\n",
    "<br>\n",
    "층 정규화를 수행한 후에는 $x_{i}$는 $ln_{i}$라는 벡터로 정규화가 됩니다.<br>\n",
    "<br>\n",
    "$ln_{i} = LayerNorm(x_{i})$\n",
    "<br>\n",
    "층 정규화의 수식을 알아봅시다. 여기서는 층 정규화를 두가지 과정으로 나누어 설명하겠습니다. <br>\n",
    "첫번째는 평균과 분산을 통한 정규화, 두번째는 감마와 베타를 도입하는 것입니다. 우선, 평균과 분산을 통해 벡터 $x_i$를 정규화해줍니다.<br>\n",
    "$x_i$는 벡터인 반면, 평균 $μ_i$과 분산 $σ^{2}_{i}$은 스칼라입니다.<br>\n",
    "벡터 $x_i$의 각 차원을 $k$라고 하였을 때, $x_{i,k}$는 다음의 수식과 같이 정규화 할 수 있습니다.<br>\n",
    "다시 말해 벡터 $x_i$의 각 $k$차원의 값이 다음과 같이 정규화 되는 것입니다.\n",
    "<br>\n",
    "$\\hat{x}_{i, k} = \\frac{x_{i, k}-μ_{i}}{\\sqrt{σ^{2}_{i}+\\epsilon}}$ <br>\n",
    "<br>\n",
    "$ϵ$(입실론)은 분모가 0이 되는 것을 방지하는 값입니다.<br>\n",
    "<br>\n",
    "이제 $γ$(감마)와 $β$(베타)라는 벡터를 준비합니다. 단, 이들의 초기값은 각각 1과 0입니다.<br>\n",
    "<br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/31379/%EA%B0%90%EB%A7%88%EB%B2%A0%ED%83%80.PNG)\n",
    "\n",
    "<br>\n",
    " $γ$와 $β$를 도입한 층 정규화의 최종 수식은 다음과 같으며  $γ$와 $β$는 학습가능한 파라미터입니다.<br>\n",
    " <br>\n",
    " $ln_{i} = γ\\hat{x}_{i}+β = LayerNorm(x_{i})$\n",
    " <br>\n",
    " \n",
    "관련 논문 : https://arxiv.org/pdf/1607.06450.pdf<br>\n",
    "<br>\n",
    "케라스에서는 층 정규화를 위한 LayerNormalization()를 제공하고 있으므로 이를 가져와 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39fd258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
