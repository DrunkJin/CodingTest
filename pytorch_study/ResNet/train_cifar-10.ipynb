{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "transforms = Compose([\n",
    "    RandomCrop((32, 32), padding=4), # Random Cropping\n",
    "    RandomHorizontalFlip(p=0.4),  # 랜덤 Y축 대칭\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std = (0.247, 0.243, 0.261)) # 이 값을 구하는 과정은 아래 마크다운 코드\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch \n",
    "\n",
    "training_data = CIFAR10(\n",
    "    root=\"../data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root=\"../data/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "imgs = [item[0] for item in training_data]\n",
    "\n",
    "# 이미지를 하나로 합침\n",
    "imgs = torch.stack(imgs, dim=0).numpy()\n",
    "\n",
    "# rgb 각 평균\n",
    "mean_r = imgs[:,0,:,:].mean()\n",
    "mean_g = imgs[:,1,:,:].mean()\n",
    "mean_b = imgs[:,2,:,:].mean()\n",
    "print(mean_r, mean_g, mean_b)\n",
    "\n",
    "# rgb 각 표준편차\n",
    "std_r = imgs[:,0,:,:].std()\n",
    "std_g = imgs[:,1,:,:].std()\n",
    "std_b = imgs[:,2,:,:].std()\n",
    "print(std_r, std_g, std_b)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 정의\n",
    "training_data = CIFAR10(root=\"../data/\", train=True, download=True, transform = transforms)\n",
    "test_data = CIFAR10(root=\"../data/\", train=True, download=False, transform = transforms)\n",
    "\n",
    "# 데이터로더 정의\n",
    "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (b1): BasicBlock(\n",
       "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (b2): BasicBlock(\n",
       "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (b3): BasicBlock(\n",
       "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ResNetModel import ResNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model = ResNet(num_classes=10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:1 loss:1.8603683710098267: 100%|██████████| 1563/1563 [01:01<00:00, 25.28it/s]\n",
      "epoch:2 loss:0.9076074361801147: 100%|██████████| 1563/1563 [01:04<00:00, 24.11it/s] \n",
      "epoch:3 loss:0.588418185710907: 100%|██████████| 1563/1563 [01:07<00:00, 23.26it/s]  \n",
      "epoch:4 loss:0.5426695346832275: 100%|██████████| 1563/1563 [01:04<00:00, 24.17it/s] \n",
      "epoch:5 loss:0.3023432791233063: 100%|██████████| 1563/1563 [01:04<00:00, 24.17it/s] \n",
      "epoch:6 loss:0.5081888437271118: 100%|██████████| 1563/1563 [01:03<00:00, 24.49it/s] \n",
      "epoch:7 loss:0.4178522825241089: 100%|██████████| 1563/1563 [01:02<00:00, 25.14it/s] \n",
      "epoch:8 loss:0.6284071207046509: 100%|██████████| 1563/1563 [01:04<00:00, 24.29it/s]  \n",
      "epoch:9 loss:0.30299443006515503: 100%|██████████| 1563/1563 [01:07<00:00, 23.33it/s]\n",
      "epoch:10 loss:0.3629690408706665: 100%|██████████| 1563/1563 [01:12<00:00, 21.51it/s] \n",
      "epoch:11 loss:0.41860073804855347: 100%|██████████| 1563/1563 [01:02<00:00, 24.87it/s] \n",
      "epoch:12 loss:0.22462643682956696: 100%|██████████| 1563/1563 [01:02<00:00, 24.92it/s]\n",
      "epoch:13 loss:0.311593234539032: 100%|██████████| 1563/1563 [01:03<00:00, 24.60it/s]   \n",
      "epoch:14 loss:0.5034598112106323: 100%|██████████| 1563/1563 [01:03<00:00, 24.59it/s]  \n",
      "epoch:15 loss:0.2852158546447754: 100%|██████████| 1563/1563 [01:03<00:00, 24.63it/s]  \n",
      "epoch:16 loss:0.04654756188392639: 100%|██████████| 1563/1563 [01:03<00:00, 24.58it/s] \n",
      "epoch:17 loss:0.1350792646408081: 100%|██████████| 1563/1563 [01:02<00:00, 25.01it/s]  \n",
      "epoch:18 loss:0.2533521354198456: 100%|██████████| 1563/1563 [01:01<00:00, 25.25it/s]  \n",
      "epoch:19 loss:0.055217742919921875: 100%|██████████| 1563/1563 [01:01<00:00, 25.37it/s]\n",
      "epoch:20 loss:0.3094571828842163: 100%|██████████| 1563/1563 [01:00<00:00, 25.93it/s]  \n",
      "epoch:21 loss:0.013885178603231907: 100%|██████████| 1563/1563 [01:01<00:00, 25.51it/s]\n",
      "epoch:22 loss:0.06379455327987671: 100%|██████████| 1563/1563 [01:05<00:00, 23.76it/s] \n",
      "epoch:23 loss:0.011360079050064087: 100%|██████████| 1563/1563 [01:08<00:00, 22.70it/s]\n",
      "epoch:24 loss:0.07635375112295151: 100%|██████████| 1563/1563 [01:08<00:00, 22.79it/s]  \n",
      "epoch:25 loss:0.04365928843617439: 100%|██████████| 1563/1563 [01:07<00:00, 23.02it/s]  \n",
      "epoch:26 loss:0.360111802816391: 100%|██████████| 1563/1563 [01:00<00:00, 25.67it/s]   \n",
      "epoch:27 loss:0.09193052351474762: 100%|██████████| 1563/1563 [01:00<00:00, 26.03it/s]  \n",
      "epoch:28 loss:0.24540364742279053: 100%|██████████| 1563/1563 [01:00<00:00, 25.90it/s]  \n",
      "epoch:29 loss:0.04598817601799965: 100%|██████████| 1563/1563 [00:59<00:00, 26.11it/s]  \n",
      "epoch:30 loss:0.022561270743608475: 100%|██████████| 1563/1563 [01:00<00:00, 26.02it/s] \n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(30):\n",
    "    iterator = tqdm.tqdm(train_loader)\n",
    "    for data, label in iterator:\n",
    "        # 최적화를 위해 기울기를 초기화\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # 모델의 예측값\n",
    "        preds = model(data.to(device))\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
    "        \n",
    "torch.save(model.state_dict(), \"ResNet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.97508\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"ResNet.pth\", map_location=device))\n",
    "\n",
    "num_corr = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        \n",
    "        output = model(data.to(device))\n",
    "        preds = output.data.max(1)[1]\n",
    "        corr = preds.eq(label.to(device).data).sum().item()\n",
    "        num_corr += corr\n",
    "\n",
    "    print(f\"Accuracy:{num_corr/len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
